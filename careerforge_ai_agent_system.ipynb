{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vZDlKcKcVpq8"
      },
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "\"\"\"\n",
        "CareerForge AI - AI-Powered Career Acceleration System\n",
        "===========================================================================\n",
        "\n",
        "This notebook implements a multi-agent system that helps job seekers:\n",
        "- Optimize resumes for ATS systems\n",
        "- Prepare for interviews with personalized questions\n",
        "- Negotiate salaries with market data\n",
        "- Research companies intelligently\n",
        "\n",
        "Author: Vaishnavi Saundankar\n",
        "Course: Kaggle 5-Day Agents Course - Capstone Project\n",
        "Track: Agents for Good (Education)\n",
        "\"\"\"\n",
        "\n",
        "%pip install -q google-genai google-adk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0929DScMXYhs",
        "outputId": "6bb94051-b363-4639-f764-94b4c5acdbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import uuid\n",
        "import inspect\n",
        "import asyncio\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "# ADK imports\n",
        "from google.adk.agents import Agent, LlmAgent\n",
        "from google.adk.models.google_llm import Gemini\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "from google.adk.memory import InMemoryMemoryService\n",
        "from google.adk.tools import ToolContext\n",
        "\n",
        "# Gemini content types\n",
        "from google.genai import types\n",
        "\n",
        "print(\"Imports loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU_yGbzFYaki",
        "outputId": "0bafd824-4947-48d0-87c4-cc6d5c145a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GOOGLE_API_KEY loaded: True\n"
          ]
        }
      ],
      "source": [
        "# Load GOOGLE_API_KEY\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not GOOGLE_API_KEY:\n",
        "    print(\"GOOGLE_API_KEY not found in environment.\")\n",
        "    GOOGLE_API_KEY = input(\"Enter your GOOGLE_API_KEY here: \").strip()\n",
        "\n",
        "# Set environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "print(\"GOOGLE_API_KEY loaded:\", bool(GOOGLE_API_KEY))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Akko72g-WFWw"
      },
      "outputs": [],
      "source": [
        "PRIMARY_MODEL = \"gemini-2.0-flash-exp\"\n",
        "\n",
        "TECH_SKILLS = [\n",
        "    \"Python\",\"Java\",\"JavaScript\",\"Go\",\"SQL\",\"AWS\",\"Azure\",\"GCP\",\"Docker\",\n",
        "    \"TensorFlow\",\"PyTorch\",\"Scikit-learn\",\"Microservices\",\"REST API\",\n",
        "    \"Kubernetes\",\"DevOps\",\"Data Pipelines\",\"Transformer\",\"Embeddings\"\n",
        "]\n",
        "\n",
        "ALL_SKILLS = list(dict.fromkeys(TECH_SKILLS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xtlGirwnWHkP"
      },
      "outputs": [],
      "source": [
        "# Custom Tools\n",
        "\n",
        "from google.adk.tools import ToolContext\n",
        "from typing import List, Dict, Any, Optional\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "async def parse_resume(\n",
        "    resume_text: str,\n",
        "    tool_context: Optional[ToolContext] = None\n",
        ") -> Dict[str, Any]:\n",
        "    resume_text = (resume_text or \"\")\n",
        "    text_lower = resume_text.lower()\n",
        "\n",
        "    found_skills = []\n",
        "    for skill in ALL_SKILLS:\n",
        "        if skill.lower() in text_lower:\n",
        "            found_skills.append(skill)\n",
        "\n",
        "    # overall experience\n",
        "    experience_match = re.search(r'(\\d+)[\\+\\s]*(?:years?|yrs)', resume_text, re.IGNORECASE)\n",
        "    experience_years = int(experience_match.group(1)) if experience_match else 0\n",
        "\n",
        "    sections = {\n",
        "        \"has_experience\": bool(re.search(r'\\b(experience|work|employment)\\b', text_lower)),\n",
        "        \"has_education\": bool(re.search(r'\\b(education|degree|university|bachelor|master)\\b', text_lower)),\n",
        "        \"has_skills\": bool(re.search(r'\\b(skills|technologies|technical)\\b', text_lower)),\n",
        "        \"has_contact\": bool(re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b', resume_text))\n",
        "    }\n",
        "\n",
        "    words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text_lower)\n",
        "    stopwords = {'the','and','for','with','this','that','from','have','will','your','experience','project','projects','skills','technical'}\n",
        "    keywords = [w for w in words if w not in stopwords]\n",
        "    top_keywords = [k for k, _ in Counter(keywords).most_common(20)]\n",
        "\n",
        "    relevant_years = 0\n",
        "    # split into sentences\n",
        "    ml_keywords = [\"machine learning\", \"ml engineer\", \"ml\", \"ai\", \"deep learning\", \"nlp\", \"natural language\", \"transformer\", \"pytorch\", \"tensorflow\", \"langchain\"]\n",
        "    sentences = re.split(r'[.\\n]+', resume_text)\n",
        "    for s in sentences:\n",
        "        s_low = s.lower()\n",
        "        if any(k in s_low for k in ml_keywords):\n",
        "            m = re.search(r'(\\d+)[\\+\\s]*(?:years?|yrs)', s_low)\n",
        "            if m:\n",
        "                try:\n",
        "                    yrs = int(m.group(1))\n",
        "                    relevant_years = max(relevant_years, yrs)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    if relevant_years == 0:\n",
        "        relevant_years = min(experience_years, 5)\n",
        "\n",
        "    return {\n",
        "        \"skills\": list(dict.fromkeys(found_skills)),\n",
        "        \"experience_years\": experience_years,\n",
        "        \"relevant_experience_years\": int(relevant_years),\n",
        "        \"sections\": sections,\n",
        "        \"word_count\": len(resume_text.split()),\n",
        "        \"top_keywords\": top_keywords\n",
        "    }\n",
        "\n",
        "\n",
        "async def parse_job_description(\n",
        "    job_text: str,\n",
        "    tool_context: Optional[ToolContext] = None\n",
        ") -> Dict[str, Any]:\n",
        "    job_text = (job_text or \"\")\n",
        "    text_lower = job_text.lower()\n",
        "\n",
        "    required_skills = []\n",
        "    preferred_skills = []\n",
        "\n",
        "    for skill in ALL_SKILLS:\n",
        "        if skill.lower() in text_lower:\n",
        "            # capture context around the match\n",
        "            context_matches = re.finditer(r'.{0,50}' + re.escape(skill.lower()) + r'.{0,50}', text_lower)\n",
        "            is_required = False\n",
        "            for match in context_matches:\n",
        "                context = match.group(0)\n",
        "                if any(kw in context for kw in [\"required\", \"must\", \"essential\"]):\n",
        "                    is_required = True\n",
        "                    break\n",
        "\n",
        "            if is_required:\n",
        "                required_skills.append(skill)\n",
        "            else:\n",
        "                preferred_skills.append(skill)\n",
        "\n",
        "    experience_match = re.search(r'(\\d+)[\\+\\-\\s]*(?:years?|yrs)', job_text, re.IGNORECASE)\n",
        "    experience_required = int(experience_match.group(1)) if experience_match else None\n",
        "\n",
        "    words = re.findall(r'\\b[a-zA-Z]{4,}\\b', text_lower)\n",
        "    stopwords = {'the', 'and', 'for', 'with', 'this', 'that', 'from', 'have', 'will', 'your'}\n",
        "    keywords = [w for w in words if w not in stopwords]\n",
        "    keyword_freq = Counter(keywords).most_common(20)\n",
        "\n",
        "    return {\n",
        "        \"required_skills\": list(dict.fromkeys(required_skills)),\n",
        "        \"preferred_skills\": list(dict.fromkeys(preferred_skills)),\n",
        "        \"experience_required\": experience_required,\n",
        "        \"top_keywords\": [k for k, _ in keyword_freq],\n",
        "        \"word_count\": len(job_text.split())\n",
        "    }\n",
        "\n",
        "\n",
        "# calculate_ats_score\n",
        "\n",
        "async def calculate_ats_score(\n",
        "    resume_data: Dict[str, Any],\n",
        "    job_data: Dict[str, Any],\n",
        "    tool_context: Optional[ToolContext] = None\n",
        ") -> Dict[str, Any]:\n",
        "    if isinstance(resume_data, str):\n",
        "        text = resume_data.lower()\n",
        "        resume_skills = set(s for s in ALL_SKILLS if s.lower() in text)\n",
        "        experience_years = 0\n",
        "        relevant_experience = 0\n",
        "    else:\n",
        "        resume_skills = set(s.lower() for s in resume_data.get(\"skills\", []))\n",
        "        experience_years = int(resume_data.get(\"experience_years\", 0) or 0)\n",
        "        relevant_experience = int(resume_data.get(\"relevant_experience_years\", 0) or 0)\n",
        "\n",
        "    if isinstance(job_data, str):\n",
        "        job_text = job_data.lower()\n",
        "        job_required = [s for s in ALL_SKILLS if s.lower() in job_text]\n",
        "        job_keywords = re.findall(r'\\b[a-zA-Z]{4,}\\b', job_text)\n",
        "    else:\n",
        "        job_required = [s.lower() for s in job_data.get(\"required_skills\", [])]\n",
        "        job_keywords = [k.lower() for k in job_data.get(\"top_keywords\", [])]\n",
        "\n",
        "    required_skills = set(s.lower() for s in job_required)\n",
        "\n",
        "    if required_skills:\n",
        "        skills_match = len(resume_skills.intersection(required_skills)) / len(required_skills) * 100\n",
        "    else:\n",
        "        skills_match = 100.0\n",
        "\n",
        "    resume_keywords = set(k.lower() for k in resume_data.get(\"top_keywords\", [])[:30]) if isinstance(resume_data, dict) else set()\n",
        "    job_keywords_set = set(job_keywords[:30]) if job_keywords else set()\n",
        "    if job_keywords_set:\n",
        "        keyword_match = len(resume_keywords.intersection(job_keywords_set)) / len(job_keywords_set) * 100\n",
        "    else:\n",
        "        keyword_match = 100.0\n",
        "\n",
        "    sections = resume_data.get(\"sections\", {}) if isinstance(resume_data, dict) else {}\n",
        "    format_score = (sum(int(bool(v)) for v in sections.values()) / len(sections) * 100) if sections else 0.0\n",
        "\n",
        "    # incorporate relevant experience into score: if job asks X years, penalize if relevant_experience < required\n",
        "    experience_required = job_data.get(\"experience_required\") if isinstance(job_data, dict) else None\n",
        "    experience_score = 100.0\n",
        "    if experience_required:\n",
        "        if relevant_experience >= experience_required:\n",
        "            experience_score = 100.0\n",
        "        else:\n",
        "            experience_score = max(0.0, (relevant_experience / experience_required) * 100)\n",
        "\n",
        "    # overall weighting: skills 45, keywords 25, format 15, experience 15\n",
        "    overall_score = (skills_match * 0.45 + keyword_match * 0.25 + format_score * 0.15 + experience_score * 0.15)\n",
        "\n",
        "    missing_skills = list(required_skills - resume_skills)\n",
        "    missing_keywords = list(job_keywords_set - resume_keywords)[:10]\n",
        "\n",
        "    suggestions = []\n",
        "    if skills_match < 70 and missing_skills:\n",
        "        suggestions.append(f\"Add or emphasize these skills: {', '.join(missing_skills[:8])}\")\n",
        "    if keyword_match < 70 and missing_keywords:\n",
        "        suggestions.append(f\"Incorporate keywords: {', '.join(missing_keywords[:8])}\")\n",
        "    if not sections.get(\"has_skills\"):\n",
        "        suggestions.append(\"Add a dedicated Skills section (concise bullet list).\")\n",
        "    if experience_required and relevant_experience < experience_required:\n",
        "        suggestions.append(f\"Add relevant coursework/projects to show experience close to required ({experience_required} yrs).\")\n",
        "\n",
        "    return {\n",
        "        \"overall_score\": round(overall_score, 1),\n",
        "        \"skills_match\": round(skills_match, 1),\n",
        "        \"keyword_match\": round(keyword_match, 1),\n",
        "        \"format_score\": round(format_score, 1),\n",
        "        \"experience_score\": round(experience_score, 1),\n",
        "        \"missing_skills\": missing_skills[:10],\n",
        "        \"missing_keywords\": missing_keywords,\n",
        "        \"suggestions\": suggestions,\n",
        "        \"pass_threshold\": overall_score >= 85\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n_eI1_O7XERj"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DFBA5nbTXxpg"
      },
      "outputs": [],
      "source": [
        "# Salary Negotiation\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote_plus\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "# REALISTIC SALARY DATA (Updated for 2024-2025)\n",
        "\n",
        "SALARY_BASE_MAP = {\n",
        "    # Entry-level (0-2 years RELEVANT experience)\n",
        "    \"ai engineer_entry\": 95000,\n",
        "    \"ml engineer_entry\": 100000,\n",
        "    \"software engineer_entry\": 85000,\n",
        "    \"data scientist_entry\": 90000,\n",
        "    \"data engineer_entry\": 88000,\n",
        "\n",
        "    # Mid-level (3-5 years)\n",
        "    \"ai engineer_mid\": 135000,\n",
        "    \"ml engineer_mid\": 145000,\n",
        "    \"software engineer_mid\": 120000,\n",
        "    \"data scientist_mid\": 125000,\n",
        "    \"data engineer_mid\": 115000,\n",
        "\n",
        "    # Senior (6-10 years)\n",
        "    \"ai engineer_senior\": 175000,\n",
        "    \"ml engineer_senior\": 185000,\n",
        "    \"software engineer_senior\": 160000,\n",
        "    \"data scientist_senior\": 165000,\n",
        "    \"data engineer_senior\": 155000,\n",
        "\n",
        "    # Lead/Staff (10+ years)\n",
        "    \"ai engineer_lead\": 220000,\n",
        "    \"ml engineer_lead\": 235000,\n",
        "    \"software engineer_lead\": 200000,\n",
        "    \"data scientist_lead\": 210000,\n",
        "}\n",
        "\n",
        "# Location multipliers\n",
        "LOCATION_MULTIPLIERS = {\n",
        "    \"san francisco\": 1.25,\n",
        "    \"sf\": 1.25,\n",
        "    \"bay area\": 1.25,\n",
        "    \"new york\": 1.22,\n",
        "    \"ny\": 1.22,\n",
        "    \"nyc\": 1.22,\n",
        "    \"seattle\": 1.18,\n",
        "    \"boston\": 1.15,\n",
        "    \"los angeles\": 1.12,\n",
        "    \"la\": 1.12,\n",
        "    \"austin\": 1.10,\n",
        "    \"chicago\": 1.08,\n",
        "    \"denver\": 1.05,\n",
        "    \"remote\": 0.95,\n",
        "    \"default\": 1.0\n",
        "}\n",
        "\n",
        "\n",
        "def determine_experience_level(relevant_years: int, total_years: int, is_transition: bool) -> str:\n",
        "    \"\"\"\n",
        "    Determine experience level considering career transitions\n",
        "\n",
        "    Args:\n",
        "        relevant_years: Years in target field\n",
        "        total_years: Total work experience\n",
        "        is_transition: Whether this is a career transition\n",
        "    \"\"\"\n",
        "    if is_transition or relevant_years <= 1:\n",
        "        return \"entry\"\n",
        "    elif relevant_years <= 2:\n",
        "        return \"entry\"\n",
        "    elif relevant_years <= 5:\n",
        "        return \"mid\"\n",
        "    elif relevant_years <= 10:\n",
        "        return \"senior\"\n",
        "    else:\n",
        "        return \"lead\"\n",
        "\n",
        "\n",
        "def normalize_position(position: str) -> str:\n",
        "    \"\"\"Normalize job title to standard format\"\"\"\n",
        "    pos_lower = position.lower()\n",
        "\n",
        "    if \"machine learning\" in pos_lower or \"ml engineer\" in pos_lower:\n",
        "        return \"ml engineer\"\n",
        "    elif \"ai engineer\" in pos_lower or \"artificial intelligence\" in pos_lower:\n",
        "        return \"ai engineer\"\n",
        "    elif \"data scientist\" in pos_lower:\n",
        "        return \"data scientist\"\n",
        "    elif \"data engineer\" in pos_lower:\n",
        "        return \"data engineer\"\n",
        "    elif \"software engineer\" in pos_lower:\n",
        "        return \"software engineer\"\n",
        "    else:\n",
        "        return \"software engineer\"  # Default\n",
        "\n",
        "\n",
        "def get_location_multiplier(location: str) -> float:\n",
        "    \"\"\"Get location salary multiplier\"\"\"\n",
        "    loc_lower = location.lower()\n",
        "\n",
        "    for key, multiplier in LOCATION_MULTIPLIERS.items():\n",
        "        if key in loc_lower:\n",
        "            return multiplier\n",
        "\n",
        "    return LOCATION_MULTIPLIERS[\"default\"]\n",
        "\n",
        "\n",
        "def calculate_base_salary(\n",
        "    position: str,\n",
        "    relevant_experience_years: int,\n",
        "    total_experience_years: int,\n",
        "    is_career_transition: bool\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Calculate base salary before location adjustment\n",
        "\n",
        "    Career transition logic:\n",
        "    - If transitioning, use entry-level salary regardless of total experience\n",
        "    - Give small bonus for transferable skills (5-10%)\n",
        "    \"\"\"\n",
        "    normalized_pos = normalize_position(position)\n",
        "    level = determine_experience_level(\n",
        "        relevant_experience_years,\n",
        "        total_experience_years,\n",
        "        is_career_transition\n",
        "    )\n",
        "\n",
        "    # Get base salary for position + level\n",
        "    key = f\"{normalized_pos}_{level}\"\n",
        "    base_salary = SALARY_BASE_MAP.get(key, SALARY_BASE_MAP.get(f\"{normalized_pos}_entry\", 90000))\n",
        "\n",
        "    # If career transition with significant prior experience, add small bonus\n",
        "    if is_career_transition and total_experience_years >= 3:\n",
        "        # 5-10% bonus for transferable skills\n",
        "        transferable_bonus = min(total_experience_years * 0.02, 0.10)  # Max 10%\n",
        "        base_salary = int(base_salary * (1 + transferable_bonus))\n",
        "\n",
        "    return base_salary\n",
        "\n",
        "\n",
        "async def salary_negotiation_analysis(\n",
        "    position: str,\n",
        "    location: str,\n",
        "    experience_years: int,\n",
        "    current_offer: Optional[int] = None,\n",
        "    relevant_experience_years: Optional[int] = None,\n",
        "    is_career_transition: bool = False,\n",
        "    tool_context: Optional[object] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Realistic salary analysis with career transition support\n",
        "\n",
        "    Args:\n",
        "        position: Job title\n",
        "        location: Job location\n",
        "        experience_years: Total years of work experience\n",
        "        current_offer: Current salary offer (if any)\n",
        "        relevant_experience_years: Years in TARGET field (None = same as experience_years)\n",
        "        is_career_transition: True if switching careers (e.g., CRM → AI)\n",
        "\n",
        "    Returns:\n",
        "        Realistic salary analysis with market data\n",
        "    \"\"\"\n",
        "\n",
        "    # If no relevant experience specified, assume all experience is relevant\n",
        "    if relevant_experience_years is None:\n",
        "        relevant_experience_years = experience_years\n",
        "\n",
        "    # Auto-detect career transition\n",
        "    if relevant_experience_years < experience_years - 1:\n",
        "        is_career_transition = True\n",
        "\n",
        "    # Calculate base salary\n",
        "    base_salary = calculate_base_salary(\n",
        "        position=position,\n",
        "        relevant_experience_years=relevant_experience_years,\n",
        "        total_experience_years=experience_years,\n",
        "        is_career_transition=is_career_transition\n",
        "    )\n",
        "\n",
        "    # Apply location multiplier\n",
        "    loc_multiplier = get_location_multiplier(location)\n",
        "    market_median = int(base_salary * loc_multiplier)\n",
        "\n",
        "    # Calculate market range (±15%)\n",
        "    market_range = (int(market_median * 0.85), int(market_median * 1.15))\n",
        "\n",
        "    # Determine experience level for messaging\n",
        "    level = determine_experience_level(\n",
        "        relevant_experience_years,\n",
        "        experience_years,\n",
        "        is_career_transition\n",
        "    )\n",
        "\n",
        "    # Build data sources\n",
        "    sources = [\n",
        "        f\"Industry data for {level}-level {normalize_position(position)}\",\n",
        "        f\"Location adjustment: {loc_multiplier}x for {location}\"\n",
        "    ]\n",
        "\n",
        "    if is_career_transition:\n",
        "        sources.append(\n",
        "            f\"Career transition adjustment: {relevant_experience_years} years relevant exp \"\n",
        "            f\"(from {experience_years} years total)\"\n",
        "        )\n",
        "\n",
        "    # Levels.fyi\n",
        "    levels_val = None\n",
        "    try:\n",
        "        # Only fetch for non-entry level to avoid skewing data\n",
        "        if level != \"entry\":\n",
        "            levels_val = await fetch_levelsfyi_safe(position, location)\n",
        "            if levels_val and 80000 <= levels_val <= 400000:  # Sanity check\n",
        "                # Blend conservatively\n",
        "                market_median = int((0.70 * market_median) + (0.30 * levels_val))\n",
        "                sources.append(f\"Levels.fyi supplementary data: ${levels_val:,}\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Recalculate range after blending\n",
        "    market_range = (int(market_median * 0.85), int(market_median * 1.15))\n",
        "\n",
        "    # Decision strategy\n",
        "    if current_offer:\n",
        "        offer_vs_median = current_offer / market_median\n",
        "\n",
        "        if offer_vs_median < 0.90:\n",
        "            # Offer is significantly below market\n",
        "            strategy = \"COUNTER_UP\"\n",
        "            target = min(int(market_median * 1.05), market_range[1])\n",
        "            confidence = 0.85\n",
        "            reasoning = (\n",
        "                f\"Current offer (${current_offer:,}) is {int((1 - offer_vs_median) * 100)}% \"\n",
        "                f\"below market median (${market_median:,}). Strong case for negotiation.\"\n",
        "            )\n",
        "\n",
        "        elif offer_vs_median > 1.10:\n",
        "            # Offer is above market\n",
        "            strategy = \"ACCEPT\"\n",
        "            target = current_offer\n",
        "            confidence = 0.90\n",
        "            reasoning = (\n",
        "                f\"Current offer (${current_offer:,}) is {int((offer_vs_median - 1) * 100)}% \"\n",
        "                f\"above market median (${market_median:,}). Excellent offer.\"\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            # Offer is close to market\n",
        "            strategy = \"NEGOTIATE_SLIGHTLY\"\n",
        "            target = int((current_offer + market_median) / 2)\n",
        "            confidence = 0.70\n",
        "            reasoning = (\n",
        "                f\"Current offer (${current_offer:,}) is within market range \"\n",
        "                f\"(${market_range[0]:,} - ${market_range[1]:,}). Room for modest negotiation.\"\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        strategy = \"WAIT_FOR_OFFER\"\n",
        "        target = market_median\n",
        "        confidence = 0.75\n",
        "        reasoning = (\n",
        "            f\"Target salary: ${market_median:,} based on {level}-level {position} \"\n",
        "            f\"in {location}\"\n",
        "        )\n",
        "        if is_career_transition:\n",
        "            reasoning += f\" (career transition with {relevant_experience_years} years relevant experience)\"\n",
        "\n",
        "    # Build raw samples\n",
        "    raw_samples = [\n",
        "        {\n",
        "            \"source\": \"industry_base\",\n",
        "            \"level\": level,\n",
        "            \"base_salary\": base_salary,\n",
        "            \"adjusted_salary\": market_median\n",
        "        }\n",
        "    ]\n",
        "    if levels_val:\n",
        "        raw_samples.append({\n",
        "            \"source\": \"levels.fyi\",\n",
        "            \"sample_comp\": levels_val\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"market_median\": market_median,\n",
        "        \"market_range\": market_range,\n",
        "        \"sources_used\": sources,\n",
        "        \"recommended_strategy\": strategy,\n",
        "        \"target_salary\": target,\n",
        "        \"confidence\": round(float(confidence), 2),\n",
        "        \"raw_samples\": raw_samples,\n",
        "        \"experience_level\": level,\n",
        "        \"is_career_transition\": is_career_transition,\n",
        "        \"relevant_years\": relevant_experience_years,\n",
        "        \"total_years\": experience_years,\n",
        "        \"reasoning\": reasoning\n",
        "    }\n",
        "\n",
        "\n",
        "async def fetch_levelsfyi_safe(position: str, location: str) -> Optional[int]:\n",
        "    \"\"\"\n",
        "    Safe wrapper for Levels.fyi fetching - returns None on any error\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return fetch_levelsfyi(position, location, max_attempts=1, pause=0.5)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def fetch_levelsfyi(position: str, location: str, max_attempts: int = 1, pause: float = 0.5) -> Optional[int]:\n",
        "    \"\"\"\n",
        "    Best-effort Levels.fyi scraper (simplified, less aggressive)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not position:\n",
        "            return None\n",
        "\n",
        "        query = f'{position} salary {location} site:levels.fyi'\n",
        "        search_url = f\"https://www.google.com/search?q={quote_plus(query)}\"\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
        "        }\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            r = requests.get(search_url, headers=headers, timeout=5)\n",
        "            if r.status_code != 200:\n",
        "                return None\n",
        "\n",
        "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "            # Find levels.fyi link\n",
        "            href = None\n",
        "            for a in soup.find_all(\"a\", href=True):\n",
        "                if \"levels.fyi\" in a.get(\"href\", \"\"):\n",
        "                    href = a.get(\"href\")\n",
        "                    break\n",
        "\n",
        "            if not href:\n",
        "                return None\n",
        "\n",
        "            # Unwrap Google redirect\n",
        "            m = re.search(r\"/url\\?q=(https?://[^&]+)\", href)\n",
        "            if m:\n",
        "                url = m.group(1)\n",
        "            else:\n",
        "                url = href\n",
        "\n",
        "            # Fetch page\n",
        "            time.sleep(pause)\n",
        "            p = requests.get(url, headers=headers, timeout=5)\n",
        "            if p.status_code != 200:\n",
        "                return None\n",
        "\n",
        "            html = p.text\n",
        "\n",
        "            # Extract salary (first big number)\n",
        "            m2 = re.search(r'\\$\\s?([\\d]{2,3}(?:,\\d{3})+)', html)\n",
        "            if m2:\n",
        "                return int(m2.group(1).replace(\",\", \"\"))\n",
        "\n",
        "            return None\n",
        "\n",
        "    except Exception:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "v8lVvNJdAhF0"
      },
      "outputs": [],
      "source": [
        "# install packages\n",
        "!pip install --quiet google-search-results beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV1PRPJ4EVjA",
        "outputId": "e7cf6cc2-3b4b-437e-c26c-b1256432b8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SERPAPI_API_KEY loaded: True\n"
          ]
        }
      ],
      "source": [
        "# API key handling\n",
        "\n",
        "SERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\") or None\n",
        "if not SERPAPI_API_KEY:\n",
        "    try:\n",
        "        from getpass import getpass\n",
        "        SERPAPI_API_KEY = getpass(\"Enter SERPAPI_API_KEY (input hidden): \").strip()\n",
        "    except Exception:\n",
        "        SERPAPI_API_KEY = input(\"Enter SERPAPI_API_KEY: \").strip()\n",
        "\n",
        "if not SERPAPI_API_KEY:\n",
        "    raise RuntimeError(\"SERPAPI_API_KEY not provided. Set env var or enter key when prompted.\")\n",
        "else:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = SERPAPI_API_KEY\n",
        "    print(\"SERPAPI_API_KEY loaded:\", bool(SERPAPI_API_KEY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "0FdBQG__FR64"
      },
      "outputs": [],
      "source": [
        "# Custom Job Scraper tool\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import asyncio\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "from serpapi import GoogleSearch\n",
        "import re\n",
        "import json\n",
        "\n",
        "def serpapi_google_jobs_search(\n",
        "    query: str,\n",
        "    location: str = \"United States\",\n",
        "    hours: int = 168,\n",
        "    num_results: int = 20,\n",
        "    verbose: bool = False\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Search using SerpAPI's Google Jobs engine with fallbacks and debug.\n",
        "\n",
        "    - Falls back to organic_results when jobs_results is empty.\n",
        "    - Handles several URL/link field variants.\n",
        "    - Optional verbose to print basic diagnostics.\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"engine\": \"google_jobs\",\n",
        "        \"q\": query,\n",
        "        \"location\": location,\n",
        "        \"api_key\": os.environ.get(\"SERPAPI_API_KEY\"),\n",
        "        \"num\": num_results,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        search = GoogleSearch(params)\n",
        "        res = search.get_dict()\n",
        "        if verbose:\n",
        "            print(\"SerpAPI top keys:\", list(res.keys())[:12])\n",
        "        if \"error\" in res:\n",
        "            if verbose:\n",
        "                print(\"SerpAPI Error:\", res[\"error\"])\n",
        "            return []\n",
        "\n",
        "        jobs_raw = res.get(\"jobs_results\") or []\n",
        "        if not jobs_raw:\n",
        "            if verbose:\n",
        "                print(\"No jobs_results - scanning organic_results fallback...\")\n",
        "            for r in (res.get(\"organic_results\") or [])[:50]:\n",
        "                title = r.get(\"title\",\"\") or \"\"\n",
        "                snippet = r.get(\"snippet\",\"\") or \"\"\n",
        "                link = r.get(\"link\") or r.get(\"displayed_link\") or \"\"\n",
        "                if any(k in (title + snippet).lower() for k in [\"job\", \"hiring\", \"position\", \"engineer\", \"developer\", \"analyst\"]):\n",
        "                    jobs_raw.append({\n",
        "                        \"title\": title,\n",
        "                        \"company_name\": r.get(\"source\") or r.get(\"displayed_link\") or \"\",\n",
        "                        \"location\": location,\n",
        "                        \"share_url\": link,\n",
        "                        \"description\": snippet\n",
        "                    })\n",
        "\n",
        "        jobs = []\n",
        "        seen_urls = set()\n",
        "        for job in jobs_raw:\n",
        "            url = (\n",
        "                job.get(\"share_url\") or job.get(\"url\") or\n",
        "                (job.get(\"apply_options\", [{}])[0].get(\"link\") if isinstance(job.get(\"apply_options\"), list) else \"\") or\n",
        "                job.get(\"link\") or job.get(\"job_link\") or job.get(\"apply_url\") or \"\"\n",
        "            )\n",
        "            if not url:\n",
        "                url = job.get(\"link\") or job.get(\"apply_url\") or \"\"\n",
        "\n",
        "            posted_ago = (\n",
        "                job.get(\"detected_extensions\", {}).get(\"posted_at\") or\n",
        "                job.get(\"posted_time\") or\n",
        "                job.get(\"date_posted\") or\n",
        "                job.get(\"timestamp\") or\n",
        "                \"\"\n",
        "            )\n",
        "            hours_ago = parse_time_ago(posted_ago)\n",
        "\n",
        "            salary = extract_salary(job)\n",
        "            location_str = job.get(\"location\") or job.get(\"job_location\") or job.get(\"location_name\") or location\n",
        "\n",
        "            # skip exact duplicate links early\n",
        "            if url and url in seen_urls:\n",
        "                continue\n",
        "\n",
        "            j = {\n",
        "                \"title\": job.get(\"title\") or job.get(\"job_title\") or \"Unknown Position\",\n",
        "                \"company\": job.get(\"company_name\") or job.get(\"company\") or job.get(\"hiringOrganization\") or \"Unknown Company\",\n",
        "                \"location\": location_str,\n",
        "                \"url\": url,\n",
        "                \"posted_hours_ago\": hours_ago or 0,\n",
        "                \"posted_time\": posted_ago or \"Recent\",\n",
        "                \"salary_range\": salary,\n",
        "                \"description\": (job.get(\"description\") or job.get(\"snippet\") or \"\")[:800],\n",
        "                \"job_id\": job.get(\"job_id\") or job.get(\"id\") or \"\",\n",
        "                \"extensions\": job.get(\"extensions\", []) or job.get(\"detected_extensions\", [])\n",
        "            }\n",
        "            if url:\n",
        "                seen_urls.add(url)\n",
        "            jobs.append(j)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"SerpAPI returned {len(jobs)} job(s) after parsing.\")\n",
        "        return jobs\n",
        "\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(\"SerpAPI Exception:\", e)\n",
        "        return []\n",
        "\n",
        "\n",
        "def parse_time_ago(time_str: str) -> Optional[int]:\n",
        "    \"\"\"Parse time strings into hours\"\"\"\n",
        "    if not time_str:\n",
        "        return None\n",
        "\n",
        "    time_str = time_str.lower()\n",
        "\n",
        "    if \"hour\" in time_str:\n",
        "        match = re.search(r'(\\d+)\\s*hour', time_str)\n",
        "        if match:\n",
        "            return int(match.group(1))\n",
        "    elif \"day\" in time_str:\n",
        "        match = re.search(r'(\\d+)\\s*day', time_str)\n",
        "        if match:\n",
        "            return int(match.group(1)) * 24\n",
        "    elif \"minute\" in time_str or \"just now\" in time_str or \"today\" in time_str:\n",
        "        return 1\n",
        "    elif \"week\" in time_str:\n",
        "        match = re.search(r'(\\d+)\\s*week', time_str)\n",
        "        if match:\n",
        "            return int(match.group(1)) * 168\n",
        "    elif \"month\" in time_str:\n",
        "        return 720\n",
        "\n",
        "    return 24\n",
        "\n",
        "\n",
        "def extract_salary(job: Dict) -> str:\n",
        "    \"\"\"Extract salary from job data\"\"\"\n",
        "    detected = job.get(\"detected_extensions\", {})\n",
        "\n",
        "    if \"salary\" in detected:\n",
        "        return detected[\"salary\"]\n",
        "\n",
        "    extensions = job.get(\"extensions\", [])\n",
        "    for ext in extensions:\n",
        "        ext_str = str(ext)\n",
        "        if \"$\" in ext_str:\n",
        "            if re.search(r'\\$[\\d,]+', ext_str):\n",
        "                return ext_str\n",
        "\n",
        "    highlights = job.get(\"job_highlights\", [])\n",
        "    for highlight in highlights:\n",
        "        items = highlight.get(\"items\", [])\n",
        "        for item in items:\n",
        "            if \"$\" in item and any(word in item.lower() for word in [\"salary\", \"pay\", \"compensation\", \"range\"]):\n",
        "                match = re.search(r'\\$[\\d,]+\\s*-?\\s*\\$?[\\d,]*', item)\n",
        "                if match:\n",
        "                    return match.group(0)\n",
        "\n",
        "    description = job.get(\"description\", \"\")\n",
        "    salary_match = re.search(r'\\$[\\d,]+(?:\\s*-\\s*\\$?[\\d,]+)?(?:\\s*(?:per year|annually|/year|/yr))?', description)\n",
        "    if salary_match:\n",
        "        return salary_match.group(0)\n",
        "\n",
        "    return \"Not specified\"\n",
        "\n",
        "\n",
        "def build_job_query(position: str, experience_years: int, include_skills: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Build optimized job search query\n",
        "\n",
        "    IMPORTANT: Keep queries simple for better results\n",
        "    \"\"\"\n",
        "    if experience_years <= 2:\n",
        "        return f'{position} entry level'\n",
        "    elif experience_years <= 5:\n",
        "        return f'{position}'\n",
        "    elif experience_years <= 8:\n",
        "        return f'{position} senior'\n",
        "    else:\n",
        "        return f'{position} senior'\n",
        "\n",
        "\n",
        "def deduplicate_jobs(jobs: List[Dict], verbose: bool = False) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Remove duplicate job postings using job_id or url fingerprint first,\n",
        "    fallback to title/company/location.\n",
        "    \"\"\"\n",
        "    seen = set()\n",
        "    unique_jobs = []\n",
        "\n",
        "    for i, job in enumerate(jobs):\n",
        "        job_id = (job.get(\"job_id\") or \"\").strip()\n",
        "        url = (job.get(\"url\") or \"\").strip()\n",
        "\n",
        "        # Create fingerprint\n",
        "        if job_id:\n",
        "            fingerprint = f\"id|{job_id}\"\n",
        "        elif url:\n",
        "            fingerprint = f\"url|{url}\"\n",
        "        else:\n",
        "            title = (job.get(\"title\") or \"\").lower().strip()\n",
        "            company = (job.get(\"company\") or \"\").lower().strip()\n",
        "            location = (job.get(\"location\") or \"\").lower().strip()\n",
        "\n",
        "            title = re.sub(r'\\s+', ' ', title).strip()\n",
        "\n",
        "            fingerprint = f\"fc|{title}|{company}|{location}\"\n",
        "\n",
        "        if fingerprint in seen:\n",
        "            if verbose:\n",
        "                print(f\"Skipping duplicate: {job.get('title')} at {job.get('company')}\")\n",
        "            continue\n",
        "\n",
        "        seen.add(fingerprint)\n",
        "        unique_jobs.append(job)\n",
        "\n",
        "    return unique_jobs\n",
        "\n",
        "def diversify_job_results(jobs: List[Dict], max_per_company: int = 2, verbose: bool = False) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Ensure diversity by limiting jobs per company.\n",
        "    \"\"\"\n",
        "    company_counts = {}\n",
        "    diverse_jobs = []\n",
        "\n",
        "    for job in jobs:\n",
        "        company = (job.get(\"company\") or \"Unknown\").lower().strip()\n",
        "        count = company_counts.get(company, 0)\n",
        "\n",
        "        if count < max_per_company:\n",
        "            diverse_jobs.append(job)\n",
        "            company_counts[company] = count + 1\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(f\"Skipping {company} (already have {count} jobs)\")\n",
        "\n",
        "\n",
        "    return diverse_jobs\n",
        "\n",
        "\n",
        "def calculate_match_score(job: Dict, skills: List[str], experience_years: int) -> int:\n",
        "    \"\"\"Calculate match score (0-100)\"\"\"\n",
        "    score = 50\n",
        "\n",
        "    if skills:\n",
        "        job_text = (\n",
        "            job.get(\"description\", \"\") + \" \" +\n",
        "            job.get(\"title\", \"\") + \" \" +\n",
        "            \" \".join(job.get(\"extensions\", []))\n",
        "        ).lower()\n",
        "\n",
        "        matched_skills = sum(1 for skill in skills if skill.lower() in job_text)\n",
        "        skill_ratio = matched_skills / len(skills) if skills else 0\n",
        "        score += int(skill_ratio * 40)\n",
        "\n",
        "    location = job.get(\"location\", \"\").lower()\n",
        "    if \"remote\" in location or \"anywhere\" in location:\n",
        "        score += 10\n",
        "    elif \"hybrid\" in location:\n",
        "        score += 5\n",
        "\n",
        "    hours_ago = job.get(\"posted_hours_ago\", 999)\n",
        "    if hours_ago <= 48:\n",
        "        score += 10\n",
        "    elif hours_ago <= 168:\n",
        "        score += 5\n",
        "\n",
        "    return min(score, 100)\n",
        "\n",
        "\n",
        "def generate_match_reason(job: Dict, skills: List[str], score: int) -> str:\n",
        "    \"\"\"Generate match reason\"\"\"\n",
        "    reasons = []\n",
        "\n",
        "    if score >= 80:\n",
        "        reasons.append(\"Excellent match\")\n",
        "    elif score >= 65:\n",
        "        reasons.append(\"Strong match\")\n",
        "    else:\n",
        "        reasons.append(\"Good match\")\n",
        "\n",
        "    job_text = (job.get(\"description\", \"\") + \" \" + job.get(\"title\", \"\")).lower()\n",
        "    matched_skills = [s for s in skills[:5] if s.lower() in job_text]\n",
        "\n",
        "    if matched_skills:\n",
        "        reasons.append(f\"skills: {', '.join(matched_skills[:3])}\")\n",
        "\n",
        "    location = job.get(\"location\", \"\")\n",
        "    if \"remote\" in location.lower():\n",
        "        reasons.append(\"Remote position\")\n",
        "\n",
        "    hours_ago = job.get(\"posted_hours_ago\", 0)\n",
        "    if hours_ago <= 48:\n",
        "        reasons.append(\"Very recent posting\")\n",
        "\n",
        "    return \" • \".join(reasons)\n",
        "\n",
        "def scrape_recent_jobs_real_sync(\n",
        "    position: str,\n",
        "    skills: List[str],\n",
        "    hours: int = 168,\n",
        "    experience_years: int = 0,\n",
        "    location: str = \"United States\",\n",
        "    num: int = 20,\n",
        "    verbose: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Synchronous job scraper with SIMPLIFIED query strategy\n",
        "    \"\"\"\n",
        "\n",
        "    query = build_job_query(position, experience_years)\n",
        "\n",
        "    # Fetch jobs from SerpAPI\n",
        "    jobs = serpapi_google_jobs_search(\n",
        "        query=query,\n",
        "        location=location,\n",
        "        hours=hours,\n",
        "        num_results=num,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    initial_count = len(jobs)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n Initial fetch: {initial_count} jobs\")\n",
        "\n",
        "    # If we STILL got 0 jobs, try even simpler\n",
        "    if initial_count == 0:\n",
        "\n",
        "        query = position\n",
        "        jobs = serpapi_google_jobs_search(\n",
        "            query=query,\n",
        "            location=location,\n",
        "            hours=hours,\n",
        "            num_results=num,\n",
        "            verbose=verbose\n",
        "        )\n",
        "        initial_count = len(jobs)\n",
        "\n",
        "    jobs = deduplicate_jobs(jobs, verbose=verbose)\n",
        "    after_dedup = len(jobs)\n",
        "\n",
        "    # Calculate match scores\n",
        "    for job in jobs:\n",
        "        match_score = calculate_match_score(job, skills, experience_years)\n",
        "        job[\"match_score\"] = match_score\n",
        "        job[\"match_reason\"] = generate_match_reason(job, skills, match_score)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  {job.get('title')[:50]:50s} Score: {match_score}/100\")\n",
        "\n",
        "    # Sort by score\n",
        "    jobs.sort(key=lambda x: x.get(\"match_score\", 0), reverse=True)\n",
        "\n",
        "    jobs = diversify_job_results(jobs, max_per_company=2, verbose=verbose)\n",
        "    after_diversification = len(jobs)\n",
        "\n",
        "    # Take top 5\n",
        "    final_jobs = jobs[:5]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"FINAL RESULTS: {len(final_jobs)} jobs\")\n",
        "        print(f\"{'='*60}\")\n",
        "        for i, job in enumerate(final_jobs, 1):\n",
        "            print(f\"{i}. {job.get('title')} - {job.get('company')}\")\n",
        "            print(f\"   Score: {job.get('match_score')}/100\")\n",
        "            print(f\"   Reason: {job.get('match_reason')}\")\n",
        "        print()\n",
        "\n",
        "    return {\n",
        "        \"total_found\": len(jobs),\n",
        "        \"jobs\": final_jobs,\n",
        "        \"search_criteria\": {\n",
        "            \"query\": query,\n",
        "            \"location\": location,\n",
        "            \"hours_filter\": f\"Last {hours} hours ({hours//24} days)\",\n",
        "            \"experience_filter\": f\"{experience_years} years\",\n",
        "            \"note\": \"Skills used for scoring, not filtering\"\n",
        "        },\n",
        "        \"debug_info\": {\n",
        "            \"initial_results\": initial_count,\n",
        "            \"after_deduplication\": after_dedup,\n",
        "            \"after_diversification\": after_diversification,\n",
        "            \"final_returned\": len(final_jobs),\n",
        "            \"query_used\": query\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "async def scrape_recent_jobs(\n",
        "    position: str,\n",
        "    skills: List[str],\n",
        "    hours: int = 168,\n",
        "    experience_years: int = 0,\n",
        "    location: str = \"United States\",\n",
        "    tool_context: Optional[object] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Async wrapper for job scraping\n",
        "    \"\"\"\n",
        "    loop = asyncio.get_event_loop()\n",
        "    return await loop.run_in_executor(\n",
        "        None,\n",
        "        scrape_recent_jobs_real_sync,\n",
        "        position,\n",
        "        skills,\n",
        "        hours,\n",
        "        experience_years,\n",
        "        location,\n",
        "        20,\n",
        "        True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1cBxVbjSXbKb"
      },
      "outputs": [],
      "source": [
        "# AGENT 1: RESUME TAILOR\n",
        "\n",
        "class ResumeTailorAgent:\n",
        "    def __init__(self):\n",
        "        self.agent = LlmAgent(\n",
        "            name=\"ResumeTailorAgent\",\n",
        "            description=\"Tailors resumes to match job descriptions without inventing facts\",\n",
        "            model=PRIMARY_MODEL,\n",
        "            tools=[parse_resume, parse_job_description],\n",
        "            instruction=(\n",
        "                \"You are an expert resume writer. IMPORTANT CONSTRAINTS:\\n\"\n",
        "                \"1) Do NOT invent or assert that the candidate worked at any company unless it already appears in the resume input. Never add new employers or dates.\\n\"\n",
        "                \"2) Produce suggested edits only. Mark any added/changed lines with the prefix '[SUGGESTED]'.\\n\"\n",
        "                \"3) Preserve the original Experience section verbatim unless the user explicitly asks to rewrite it.\\n\"\n",
        "                \"4) Use outputs from parse_resume and parse_job_description tools when available and never 'hallucinate' skills or employment.\\n\"\n",
        "                \"5) Return two sections: 'suggested_changes' (bullet list) and 'safe_draft' (the original resume with suggested sections appended but not altering existing employers).\\n\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    async def tailor_resume(self, resume: str, job_description: str) -> Dict[str, Any]:\n",
        "        session_service = InMemorySessionService()\n",
        "        memory_service = InMemoryMemoryService()\n",
        "        runner = Runner(app_name=\"careerforge\", agent=self.agent,\n",
        "                        session_service=session_service, memory_service=memory_service)\n",
        "        user_id = \"user_1\"\n",
        "        session_id = f\"tailor_{uuid.uuid4().hex[:8]}\"\n",
        "        # ensure session exists\n",
        "        try:\n",
        "            await session_service.create_session(app_name=\"careerforge\", user_id=user_id, session_id=session_id)\n",
        "        except Exception:\n",
        "            try:\n",
        "                await session_service.get_session(app_name=\"careerforge\", user_id=user_id, session_id=session_id)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        resume_data = await parse_resume(resume)\n",
        "        job_data = await parse_job_description(job_description)\n",
        "        query = (\n",
        "            f\"Resume (DO NOT invent employment):\\n{resume}\\n\\n\"\n",
        "            f\"Resume parsed metadata (json):\\n{json.dumps(resume_data, indent=2)}\\n\\n\"\n",
        "            f\"Job description parsed metadata (json):\\n{json.dumps(job_data, indent=2)}\\n\\n\"\n",
        "            \"Task: Suggest concrete, prioritized edits (exact lines or bullets) to make the resume match the job. \"\n",
        "            \"Mark added lines with [SUGGESTED]. Do NOT change existing 'Experience' company names or dates. \"\n",
        "            \"Return JSON with keys: suggested_changes (list of strings), safe_draft (full resume text with suggested sections appended or marked).\"\n",
        "        )\n",
        "\n",
        "        content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "        result_text = \"\"\n",
        "        async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "            if event and event.content:\n",
        "                for part in event.content.parts:\n",
        "                    if hasattr(part, \"text\") and part.text:\n",
        "                        result_text += part.text\n",
        "\n",
        "        parsed = None\n",
        "        try:\n",
        "            parsed = json.loads(result_text)\n",
        "        except Exception:\n",
        "            parsed = {\"raw\": result_text}\n",
        "\n",
        "        return {\"tailored_resume\": parsed, \"resume_data\": resume_data, \"job_data\": job_data}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mKQeQiMeXd3P"
      },
      "outputs": [],
      "source": [
        "# AGENT 2: ATS SCORER\n",
        "\n",
        "class ATSScorerAgent:\n",
        "    def __init__(self):\n",
        "        self.agent = LlmAgent(\n",
        "            name=\"ATSScorerAgent\",\n",
        "            description=\"Scores resume ATS compatibility\",\n",
        "            model=PRIMARY_MODEL,\n",
        "            tools=[parse_resume, parse_job_description, calculate_ats_score],\n",
        "            instruction=\"You are an ATS expert. Provide exact-line edits based on the ATS score.\"\n",
        "        )\n",
        "\n",
        "    async def score_and_improve(self, resume: str, job_description: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        FIXED: Calls tools directly, then uses LLM for suggestions\n",
        "        \"\"\"\n",
        "        # Step 1: Parse resume and job\n",
        "        try:\n",
        "            resume_data = await parse_resume(str(resume))\n",
        "            job_data = await parse_job_description(str(job_description))\n",
        "\n",
        "            # Step 2: Calculate score\n",
        "            ats_result = await calculate_ats_score(resume_data, job_data)\n",
        "\n",
        "            # If already passing, return early\n",
        "            if ats_result.get(\"pass_threshold\"):\n",
        "                return {\n",
        "                    \"ats_analysis\": ats_result,\n",
        "                    \"notes\": \"Score above 85% - minimal changes needed\"\n",
        "                }\n",
        "\n",
        "            # Step 3: Get LLM suggestions\n",
        "            session_service = InMemorySessionService()\n",
        "            memory_service = InMemoryMemoryService()\n",
        "            runner = Runner(\n",
        "                app_name=\"careerforge\",\n",
        "                agent=self.agent,\n",
        "                session_service=session_service,\n",
        "                memory_service=memory_service\n",
        "            )\n",
        "\n",
        "            user_id = \"user_1\"\n",
        "            session_id = f\"ats_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "            try:\n",
        "                await session_service.create_session(\n",
        "                    app_name=\"careerforge\",\n",
        "                    user_id=user_id,\n",
        "                    session_id=session_id\n",
        "                )\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            prompt = f\"\"\"ATS Score Results:\n",
        "{json.dumps(ats_result, indent=2)}\n",
        "\n",
        "Original Resume:\n",
        "{resume}\n",
        "\n",
        "Provide 3-5 specific line edits to improve the score. Return JSON with:\n",
        "- overall_score\n",
        "- missing_skills\n",
        "- recommended_changes (list of exact edits)\"\"\"\n",
        "\n",
        "            content = types.Content(role=\"user\", parts=[types.Part(text=prompt)])\n",
        "            response_text = \"\"\n",
        "\n",
        "            async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "                if event and event.content:\n",
        "                    for part in event.content.parts:\n",
        "                        if hasattr(part, \"text\") and part.text:\n",
        "                            response_text += part.text\n",
        "\n",
        "            # Parse LLM response\n",
        "            try:\n",
        "                parsed = json.loads(response_text.strip())\n",
        "                return {\"ats_analysis\": parsed, \"raw_score\": ats_result}\n",
        "            except:\n",
        "                return {\"ats_analysis\": response_text, \"raw_score\": ats_result}\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"ATS Scorer failed: {str(e)}\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "A9Z4hj-dXiNE"
      },
      "outputs": [],
      "source": [
        "# AGENT 3: JOB SCRAPER\n",
        "\n",
        "class JobScraperAgent:\n",
        "    def __init__(self):\n",
        "        self.agent = LlmAgent(\n",
        "            name=\"JobScraperAgent\",\n",
        "            description=\"Finds recently posted jobs from real job sites\",\n",
        "            model=PRIMARY_MODEL,\n",
        "            tools=[scrape_recent_jobs, parse_resume],\n",
        "            instruction=(\n",
        "                \"Primary job discovery is done via the scrape_recent_jobs tool. \"\n",
        "                \"Use parse_resume to get candidate skills. \"\n",
        "                \"Return top matches with match_score and match_reason. \"\n",
        "                \"Do NOT invent job postings.\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    async def find_jobs(\n",
        "        self,\n",
        "        resume: str,\n",
        "        target_position: str,\n",
        "        location: str = \"United States\",\n",
        "        hours: int = 168,\n",
        "        max_results: int = 5\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Deterministic job finder that returns stable JSON\n",
        "        \"\"\"\n",
        "        # 1. Parse resume to extract skills & experience\n",
        "        try:\n",
        "            resume_data = await parse_resume(resume)\n",
        "            skills = resume_data.get(\"skills\", []) or []\n",
        "            rel_exp = int(resume_data.get(\"relevant_experience_years\", 0) or 0)\n",
        "            total_exp = int(resume_data.get(\"experience_years\", 0) or 0)\n",
        "        except Exception as e:\n",
        "            print(f\"Resume parsing failed: {e}\")\n",
        "            skills = []\n",
        "            rel_exp = 0\n",
        "            total_exp = 0\n",
        "\n",
        "        # 2. Call scraper directly\n",
        "        try:\n",
        "            scraped = await scrape_recent_jobs(\n",
        "                position=target_position,\n",
        "                skills=skills,\n",
        "                hours=hours,\n",
        "                experience_years=rel_exp or total_exp,\n",
        "                location=location\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Scraper failed: {e}\")\n",
        "            return {\n",
        "                \"top_matches\": [],\n",
        "                \"error\": f\"scrape_recent_jobs failed: {type(e).__name__}: {e}\"\n",
        "            }\n",
        "\n",
        "        # 3. Extract jobs from scraper response\n",
        "        jobs = []\n",
        "        if isinstance(scraped, dict):\n",
        "            jobs = scraped.get(\"jobs\") or scraped.get(\"job_matches\") or scraped.get(\"top_matches\") or []\n",
        "        elif isinstance(scraped, list):\n",
        "            jobs = scraped\n",
        "\n",
        "        if not jobs:\n",
        "            print(f\"Scraper returned 0 jobs\")\n",
        "            return {\n",
        "                \"top_matches\": [],\n",
        "                \"debug_info\": {\n",
        "                    \"scraper_response\": scraped,\n",
        "                    \"position\": target_position,\n",
        "                    \"skills\": skills,\n",
        "                    \"location\": location\n",
        "                }\n",
        "            }\n",
        "\n",
        "        # 4. Already deduplicated and scored by scraper\n",
        "        for job in jobs:\n",
        "            if \"match_score\" not in job:\n",
        "                try:\n",
        "                    job[\"match_score\"] = calculate_match_score(job, skills, rel_exp)\n",
        "                except Exception:\n",
        "                    job[\"match_score\"] = 50\n",
        "\n",
        "            if \"match_reason\" not in job:\n",
        "                try:\n",
        "                    job[\"match_reason\"] = generate_match_reason(job, skills, job.get(\"match_score\", 50))\n",
        "                except Exception:\n",
        "                    job[\"match_reason\"] = \"Match based on job requirements\"\n",
        "\n",
        "        # 5. Sort by score and return top results\n",
        "        jobs.sort(key=lambda x: x.get(\"match_score\", 0), reverse=True)\n",
        "        top_jobs = jobs[:max_results]\n",
        "\n",
        "        print(f\"Returning {len(top_jobs)} jobs (from {len(jobs)} total)\")\n",
        "\n",
        "        return {\n",
        "            \"top_matches\": top_jobs,\n",
        "            \"total_found\": len(jobs),\n",
        "            \"search_criteria\": {\n",
        "                \"position\": target_position,\n",
        "                \"location\": location,\n",
        "                \"hours\": hours,\n",
        "                \"skills_used\": skills[:5],\n",
        "                \"experience_years\": rel_exp or total_exp\n",
        "            },\n",
        "            \"debug_info\": {\n",
        "                \"scraper_returned\": len(jobs),\n",
        "                \"final_returned\": len(top_jobs),\n",
        "                \"skills_matched\": skills[:10]\n",
        "            }\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "tRop2wwjXmU2"
      },
      "outputs": [],
      "source": [
        "# AGENT 4: INTERVIEW INTELLIGENCE\n",
        "\n",
        "class InterviewIntelligenceAgent:\n",
        "    def __init__(self):\n",
        "        self.agent = LlmAgent(\n",
        "            name=\"InterviewIntelligenceAgent\",\n",
        "            description=\"Researches companies and generates interview questions\",\n",
        "            model=PRIMARY_MODEL,\n",
        "            tools=[parse_job_description],\n",
        "            instruction=\"\"\"You prepare candidates for interviews.\n",
        "1. Parse job description to extract core skills and responsibilities.\n",
        "2. Generate 5 technical and 5 behavioral questions tailored to the role.\n",
        "3. For each question provide why they ask it, key points to cover, and a short example/framework answer.\n",
        "4. Summarize 3 company-specific talking points.\n",
        "Return structured output with keys: technical_questions, behavioral_questions, company_insights, talking_points.\"\"\"\n",
        "        )\n",
        "\n",
        "    async def prepare_interview(self, job_description: str, company_name: str) -> Dict[str, Any]:\n",
        "        session_service = InMemorySessionService()\n",
        "        memory_service = InMemoryMemoryService()\n",
        "\n",
        "        runner = Runner(\n",
        "            app_name=\"careerforge\",\n",
        "            agent=self.agent,\n",
        "            session_service=session_service,\n",
        "            memory_service=memory_service\n",
        "        )\n",
        "\n",
        "        user_id = \"user_1\"\n",
        "        session_id = f\"interview_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "        try:\n",
        "            session = await session_service.create_session(\n",
        "                app_name=\"careerforge\",\n",
        "                user_id=user_id,\n",
        "                session_id=session_id\n",
        "            )\n",
        "        except Exception:\n",
        "            session = await session_service.get_session(\n",
        "                app_name=\"careerforge\",\n",
        "                user_id=user_id,\n",
        "                session_id=session_id\n",
        "            )\n",
        "\n",
        "        query = f\"\"\"Prepare interview materials for {company_name}.\n",
        "\n",
        "JOB DESCRIPTION:\n",
        "{job_description}\n",
        "\n",
        "Instructions:\n",
        "- Parse the job description to extract responsibilities and required skills.\n",
        "- Generate 5 technical and 5 behavioral questions tailored to the role.\n",
        "- For each question include: why asked, key points to include, and a short example answer.\n",
        "- Provide 3 company-specific talking points.\n",
        "Return structured output with keys: technical_questions, behavioral_questions, company_insights, talking_points.\"\"\"\n",
        "        content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "        response_text = \"\"\n",
        "\n",
        "        async for event in runner.run_async(user_id=user_id, session_id=session.id, new_message=content):\n",
        "            if event and event.content:\n",
        "                for part in event.content.parts:\n",
        "                    if hasattr(part, \"text\") and part.text:\n",
        "                        response_text += part.text\n",
        "\n",
        "        return {\"interview_prep\": response_text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NoZVt7MgX3tr"
      },
      "outputs": [],
      "source": [
        "# AGENT 5: SALARY NEGOTIATION\n",
        "\n",
        "class SalaryNegotiationAgent:\n",
        "    def __init__(self):\n",
        "        self.agent = LlmAgent(\n",
        "            name=\"SalaryNegotiationAgent\",\n",
        "            description=\"Creates realistic negotiation strategy for career transitions and standard roles\",\n",
        "            model=PRIMARY_MODEL,\n",
        "            tools=[salary_negotiation_analysis, parse_job_description, parse_resume],\n",
        "            instruction=(\n",
        "                \"You are a compensation negotiation expert specializing in career transitions. \"\n",
        "                \"CRITICAL: Parse the resume to determine if this is a career transition (e.g., CRM → AI). \"\n",
        "                \"Use relevant_experience_years (years in TARGET field) vs total_experience_years. \"\n",
        "                \"Base ALL salary recommendations on the tool output - never invent numbers. \"\n",
        "                \"Return JSON with: target_range, counter_offer, fallback_offer, walk_away_point, \"\n",
        "                \"confidence, conversation_scripts, reasoning.\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    async def create_strategy(\n",
        "        self,\n",
        "        job_description: str,\n",
        "        company_name: str,\n",
        "        current_offer: Optional[int] = None,\n",
        "        experience_years: int = None,\n",
        "        target_position: Optional[str] = None,\n",
        "        resume: Optional[str] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Creates realistic salary negotiation strategy\n",
        "        Handles career transitions properly\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. Parse resume to detect career transition\n",
        "        parsed_resume = {}\n",
        "        relevant_exp = 0\n",
        "        total_exp = 0\n",
        "        is_transition = False\n",
        "\n",
        "        if resume:\n",
        "            try:\n",
        "                parsed_resume = await parse_resume(resume)\n",
        "\n",
        "                if isinstance(parsed_resume, dict):\n",
        "                    # Extract experience data\n",
        "                    relevant_exp = int(parsed_resume.get(\"relevant_experience_years\", 0))\n",
        "                    total_exp = int(parsed_resume.get(\"experience_years\", 0))\n",
        "\n",
        "                    # Detect career transition\n",
        "                    if relevant_exp < total_exp - 1:\n",
        "                        is_transition = True\n",
        "\n",
        "                    # Check for transition keywords in summary\n",
        "                    summary = str(parsed_resume.get(\"summary\", \"\")).lower()\n",
        "                    if any(word in summary for word in [\"transition\", \"seeking\", \"aspiring\", \"pivoting\"]):\n",
        "                        is_transition = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Resume parsing error: {e}\")\n",
        "\n",
        "        # Use provided experience_years as fallback\n",
        "        if total_exp == 0 and experience_years:\n",
        "            total_exp = experience_years\n",
        "\n",
        "        # 2. Parse job description\n",
        "        job_data = {}\n",
        "        try:\n",
        "            job_data = await parse_job_description(job_description)\n",
        "        except Exception as e:\n",
        "            job_data = {\"error\": f\"parse_job_description failed: {e}\"}\n",
        "\n",
        "        # 3. Extract position and location\n",
        "        def extract_title_from_text(text: str) -> Optional[str]:\n",
        "            if not text:\n",
        "                return None\n",
        "            m = re.search(\n",
        "                r'\\b(?:senior|lead|principal|staff|junior|associate)?\\s*'\n",
        "                r'(ai|ml|machine learning|data|software)\\s*'\n",
        "                r'(engineer|scientist|analyst)\\b',\n",
        "                text,\n",
        "                flags=re.IGNORECASE\n",
        "            )\n",
        "            if m:\n",
        "                return m.group(0).strip().title()\n",
        "            return None\n",
        "\n",
        "        def extract_location_from_text(text: str) -> Optional[str]:\n",
        "            if not text:\n",
        "                return None\n",
        "            patterns = [\n",
        "                r\"San Francisco,?\\s*CA\", r\"New York,?\\s*NY\", r\"Seattle,?\\s*WA\",\n",
        "                r\"Chicago,?\\s*IL\", r\"Boston,?\\s*MA\", r\"Austin,?\\s*TX\",\n",
        "                r\"Remote\", r\"Hybrid\"\n",
        "            ]\n",
        "            for p in patterns:\n",
        "                m = re.search(p, text, flags=re.IGNORECASE)\n",
        "                if m:\n",
        "                    return m.group(0)\n",
        "            return None\n",
        "\n",
        "        position = extract_title_from_text(job_description) or target_position or \"Software Engineer\"\n",
        "        location = extract_location_from_text(job_description) or \"Remote\"\n",
        "\n",
        "        # Override with job_data if available\n",
        "        if isinstance(job_data, dict):\n",
        "            position = job_data.get(\"job_title\") or position\n",
        "            location = job_data.get(\"location\") or location\n",
        "\n",
        "        position = str(position).strip()\n",
        "        location = str(location).strip()\n",
        "\n",
        "        # 4. Call salary analysis tool with career transition parameters\n",
        "        try:\n",
        "            salary_analysis = await salary_negotiation_analysis(\n",
        "                position=position,\n",
        "                location=location,\n",
        "                experience_years=total_exp,\n",
        "                relevant_experience_years=relevant_exp,\n",
        "                is_career_transition=is_transition,\n",
        "                current_offer=current_offer\n",
        "            )\n",
        "        except Exception as e:\n",
        "            salary_analysis = {\"error\": f\"salary_negotiation_analysis failed: {e}\"}\n",
        "\n",
        "        # 5. Build prompt for LLM\n",
        "        transition_note = \"\"\n",
        "        if is_transition:\n",
        "            transition_note = f\"\"\"\n",
        "⚠️ CAREER TRANSITION DETECTED:\n",
        "- Total experience: {total_exp} years\n",
        "- Relevant experience in {position}: {relevant_exp} years\n",
        "- Salary recommendation is for ENTRY-LEVEL {position} with transferable skills bonus\n",
        "\"\"\"\n",
        "\n",
        "        prompt_parts = [\n",
        "            \"You are a compensation negotiation expert. Use ONLY the salary analysis below.\",\n",
        "            f\"Company: {company_name}\",\n",
        "            f\"Position: {position}\",\n",
        "            f\"Location: {location}\",\n",
        "            transition_note,\n",
        "            f\"Current offer: ${current_offer:,}\" if current_offer else \"Current offer: None\",\n",
        "            \"\\nSalary Analysis (from tool):\",\n",
        "            json.dumps(salary_analysis, indent=2),\n",
        "            \"\\nTask: Create negotiation strategy JSON with:\",\n",
        "            \"- target_range: string (e.g., '$95k-$110k')\",\n",
        "            \"- counter_offer: int\",\n",
        "            \"- fallback_offer: int\",\n",
        "            \"- walk_away_point: int\",\n",
        "            \"- confidence: float (0-1)\",\n",
        "            \"- conversation_scripts: list of 3-4 short negotiation phrases\",\n",
        "            \"- reasoning: 2-3 sentence explanation\",\n",
        "            \"\\nReturn ONLY valid JSON, no markdown.\"\n",
        "        ]\n",
        "\n",
        "        prompt = \"\\n\\n\".join(prompt_parts)\n",
        "\n",
        "        # 6. Run LLM agent\n",
        "        session_service = InMemorySessionService()\n",
        "        memory_service = InMemoryMemoryService()\n",
        "        runner = Runner(\n",
        "            app_name=\"careerforge\",\n",
        "            agent=self.agent,\n",
        "            session_service=session_service,\n",
        "            memory_service=memory_service\n",
        "        )\n",
        "\n",
        "        user_id = \"user_1\"\n",
        "        session_id = f\"salary_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "        try:\n",
        "            await session_service.create_session(\n",
        "                app_name=\"careerforge\",\n",
        "                user_id=user_id,\n",
        "                session_id=session_id\n",
        "            )\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        content = types.Content(role=\"user\", parts=[types.Part(text=prompt)])\n",
        "        response_text = \"\"\n",
        "\n",
        "        try:\n",
        "            async for event in runner.run_async(\n",
        "                user_id=user_id,\n",
        "                session_id=session_id,\n",
        "                new_message=content\n",
        "            ):\n",
        "                if event and event.content:\n",
        "                    for part in event.content.parts:\n",
        "                        if hasattr(part, \"text\") and part.text:\n",
        "                            response_text += part.text\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"negotiation_strategy\": {\"error\": f\"LLM failed: {e}\"},\n",
        "                \"analysis\": salary_analysis,\n",
        "                \"job_data\": job_data\n",
        "            }\n",
        "\n",
        "        # 7. Parse LLM response\n",
        "        parsed = None\n",
        "        try:\n",
        "            clean = response_text.strip()\n",
        "            clean = re.sub(r\"^```(?:json)?\\s*\", \"\", clean)\n",
        "            clean = re.sub(r\"\\s*```$\", \"\", clean)\n",
        "            parsed = json.loads(clean)\n",
        "        except Exception:\n",
        "            parsed = {\"raw\": response_text}\n",
        "\n",
        "        return {\n",
        "            \"negotiation_strategy\": parsed,\n",
        "            \"analysis\": salary_analysis,\n",
        "            \"job_data\": job_data,\n",
        "            \"career_transition_detected\": is_transition,\n",
        "            \"experience_breakdown\": {\n",
        "                \"total_years\": total_exp,\n",
        "                \"relevant_years\": relevant_exp\n",
        "            }\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "2stywhUWX-Ur"
      },
      "outputs": [],
      "source": [
        "# SYSTEM ORCHESTRATOR\n",
        "\n",
        "class CareerForgeSystem:\n",
        "    def __init__(self):\n",
        "        self.agent1 = ResumeTailorAgent()\n",
        "        self.agent2 = ATSScorerAgent()\n",
        "        self.agent3 = JobScraperAgent()\n",
        "        self.agent4 = InterviewIntelligenceAgent()\n",
        "        self.agent5 = SalaryNegotiationAgent()\n",
        "        print(\"✅ CareerForge AI System initialized with 5 agents\")\n",
        "\n",
        "    async def run_full_workflow(\n",
        "        self,\n",
        "        resume: str,\n",
        "        target_position: str,\n",
        "        job_description: Optional[str] = None,\n",
        "        company_name: Optional[str] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        results = {}\n",
        "\n",
        "        print(\"\\n🔍 Step 1/5: Searching for jobs...\")\n",
        "        try:\n",
        "            jobs_result = await self.agent3.find_jobs(resume=resume, target_position=target_position)\n",
        "            if \"error\" in jobs_result:\n",
        "                results[\"job_search_error\"] = jobs_result[\"error\"]\n",
        "            else:\n",
        "                results[\"job_search\"] = jobs_result.get(\"top_matches\") or jobs_result.get(\"job_matches\") or jobs_result.get(\"jobs\") or jobs_result\n",
        "        except Exception as e:\n",
        "            results[\"job_search_error\"] = f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "        if not job_description:\n",
        "            return results\n",
        "\n",
        "        print(\"📝 Step 2/5: Tailoring resume...\")\n",
        "        try:\n",
        "            tailor_result = await self.agent1.tailor_resume(resume=resume, job_description=job_description)\n",
        "            if \"error\" in tailor_result:\n",
        "                results[\"tailored_resume_error\"] = tailor_result[\"error\"]\n",
        "                tailored_resume_text = resume\n",
        "            else:\n",
        "                tailored_resume_text = tailor_result.get(\"tailored_resume\", resume)\n",
        "                results[\"tailored_resume\"] = tailored_resume_text\n",
        "        except Exception as e:\n",
        "            results[\"tailored_resume_error\"] = f\"{type(e).__name__}: {e}\"\n",
        "            tailored_resume_text = resume\n",
        "\n",
        "        print(\"🎯 Step 3/5: Scoring ATS compatibility...\")\n",
        "        try:\n",
        "            ats_result = await self.agent2.score_and_improve(resume=tailored_resume_text, job_description=job_description)\n",
        "            if \"error\" in ats_result:\n",
        "                results[\"ats_analysis_error\"] = ats_result[\"error\"]\n",
        "            else:\n",
        "                results[\"ats_analysis\"] = ats_result.get(\"ats_analysis\", ats_result)\n",
        "        except Exception as e:\n",
        "            results[\"ats_analysis_error\"] = f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "        if not company_name:\n",
        "            return results\n",
        "\n",
        "        print(\"💼 Step 4/5: Preparing interview materials...\")\n",
        "        try:\n",
        "            interview_result = await self.agent4.prepare_interview(job_description=job_description, company_name=company_name)\n",
        "            if \"error\" in interview_result:\n",
        "                results[\"interview_prep_error\"] = interview_result[\"error\"]\n",
        "            else:\n",
        "                results[\"interview_prep\"] = interview_result.get(\"interview_prep\", interview_result)\n",
        "        except Exception as e:\n",
        "            results[\"interview_prep_error\"] = f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "        print(\"💰 Step 5/5: Creating negotiation strategy...\")\n",
        "        try:\n",
        "            salary_result = await self.agent5.create_strategy(\n",
        "                job_description=job_description,\n",
        "                company_name=company_name,\n",
        "                current_offer=None,\n",
        "                experience_years=5\n",
        "            )\n",
        "            if \"error\" in salary_result:\n",
        "                results[\"salary_strategy_error\"] = salary_result[\"error\"]\n",
        "            else:\n",
        "                results[\"salary_strategy\"] = salary_result.get(\"negotiation_strategy\", salary_result)\n",
        "        except Exception as e:\n",
        "            results[\"salary_strategy_error\"] = f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "MkJ_bYXSYFCH"
      },
      "outputs": [],
      "source": [
        "# DEMO\n",
        "\n",
        "SAMPLE_RESUME_BEFORE = \"\"\"\n",
        "Alex Johnson\n",
        "San Francisco, CA | (555) 123-9876 | alex.johnson.ai@gmail.com\n",
        "GitHub: github.com/alex-ml | LinkedIn: linkedin.com/in/alex-johnson-ml\n",
        "\n",
        "Summary\n",
        "AI/ML Engineer with strong experience designing, training, and deploying machine learning and LLM-based systems.\n",
        "Hands-on background in deep learning, NLP, GenAI, RAG pipelines, and cloud-native deployments (AWS/GCP/Azure).\n",
        "Experienced in full ML lifecycle including data engineering, model development, evaluation, and production deployment.\n",
        "\n",
        "Technical Skills\n",
        "Programming: Python, SQL, JavaScript\n",
        "ML/DL: PyTorch, TensorFlow, scikit-learn, XGBoost, HuggingFace Transformers\n",
        "NLP/GenAI: LLM Fine-tuning, Prompt Engineering, RAG, Vector Databases (FAISS, Pinecone)\n",
        "Cloud: AWS (SageMaker, Lambda), GCP (Vertex AI), Azure ML\n",
        "Tools: Docker, Kubernetes, Git, CI/CD, Airflow, MLflow\n",
        "Data Engineering: Pandas, Spark, ETL Pipelines\n",
        "\n",
        "Experience\n",
        "Machine Learning Engineer\n",
        "TechNova AI — San Francisco, CA\n",
        "Jan 2023 – Present\n",
        "– Designed and deployed LLM-powered chatbots and intelligent assistants using LangChain and custom RAG pipelines.\n",
        "– Built classification and recommendation models using PyTorch/TensorFlow, improving accuracy by 18–25%.\n",
        "– Created REST API microservices for inference with <120ms latency at scale.\n",
        "– Implemented monitoring pipelines and ML observability dashboards reducing model drift incidents by 30%.\n",
        "– Deployed ML systems using AWS SageMaker and Azure ML with automated CI/CD.\n",
        "\n",
        "AI Engineer Intern\n",
        "CloudWorks Intelligence — Seattle, WA\n",
        "Jun 2022 – Dec 2022\n",
        "– Implemented transformer-based NLP models for summarization and information extraction.\n",
        "– Fine-tuned BERT/T5 models improving F1-score by 14% on domain-specific datasets.\n",
        "– Deployed models using Docker + GCP Vertex AI and Cloud Run.\n",
        "– Built automated ETL workflows using Airflow for training data pipelines.\n",
        "\n",
        "Projects\n",
        "Generative AI Knowledge Assistant (LLM + RAG)\n",
        "– Built a RAG-based retrieval system using FAISS + LangChain achieving 87% retrieval accuracy.\n",
        "– Integrated HuggingFace embeddings and a fine-tuned LLaMA model with prompt optimization.\n",
        "\n",
        "Image Captioning System (CNN-LSTM + Attention)\n",
        "– Designed a CNN-LSTM attention model on Flickr8k dataset achieving BLEU score of 0.53.\n",
        "\n",
        "ML-Powered Customer Churn Prediction\n",
        "– Developed feature engineering pipelines and trained XGBoost & ANN models achieving ROC-AUC of 0.91.\n",
        "\n",
        "Education\n",
        "M.S. in Computer Science\n",
        "University of Washington — 2021–2023\n",
        "\n",
        "Certifications\n",
        "AWS Machine Learning Specialty\n",
        "TensorFlow Developer Certificate\n",
        "DeepLearning.AI NLP Specialization\n",
        "\"\"\"\n",
        "\n",
        "SAMPLE_JOB = \"\"\"\n",
        "San Francisco, California\n",
        "$110K/yr – $120K/yr\n",
        "\n",
        "Capgemini Engineering\n",
        "AI Engineer\n",
        "\n",
        "Responsibilities\n",
        "Design, develop, and deploy AI/ML models and Generative AI applications for production use cases.\n",
        "Build end-to-end AI systems including data pipelines, model training infrastructure, and inference APIs.\n",
        "Develop intelligent applications using Large Language Models (AI agents, chatbots, RAG systems, automation workflows).\n",
        "Integrate AI models into applications through REST APIs, microservices, and cloud-native architectures.\n",
        "Deploy and manage models on cloud platforms (Azure, AWS, or GCP) with focus on scalability and reliability.\n",
        "Collaborate with cross-functional teams to translate business requirements into technical solutions.\n",
        "Write clean, well-documented code and participate in code reviews.\n",
        "Stay current with the latest research and emerging trends in AI/ML and LLMs.\n",
        "\n",
        "Required\n",
        "Bachelor's degree in Computer Science, Engineering, AI, Data Science, or related field.\n",
        "Strong coursework in machine learning, deep learning, algorithms, and data structures.\n",
        "Proficiency in Python programming with core libraries (NumPy, pandas, Matplotlib).\n",
        "Experience with ML frameworks: TensorFlow, PyTorch, or scikit-learn.\n",
        "Understanding of transformer architectures, embeddings, and how LLMs work.\n",
        "Familiarity with REST APIs, vector databases, and prompt engineering concepts.\n",
        "Knowledge of cloud AI platforms (Azure, AWS, or GCP).\n",
        "Strong problem-solving, communication, and teamwork skills.\n",
        "Hands-on experience through internships, co-ops, academic projects, or personal portfolio.\n",
        "\n",
        "Preferred\n",
        "Experience with Large Language Models (GPT, Claude, Llama) and OpenAI APIs or Hugging Face Transformers.\n",
        "Familiarity with LLM frameworks (LangChain, LlamaIndex, Semantic Kernel).\n",
        "Familiarity with Agentic AI frameworks (LangGraph, Pydantic, Strands, ADK).\n",
        "Experience building AI agents, multi-agent systems, or autonomous workflows.\n",
        "Knowledge of RAG (Retrieval-Augmented Generation) systems and vector databases.\n",
        "Production deployment experience on Azure ML, AWS SageMaker, or GCP Vertex AI.\n",
        "Understanding of Git, Docker, CI/CD practices, and MLOps tools.\n",
        "Experience with model fine-tuning or training from scratch.\n",
        "GitHub portfolio with documented AI/ML projects.\n",
        "Kaggle competitions, hackathons, or open-source contributions.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkmQLgfIYJOW",
        "outputId": "a936eb56-c0ed-4c69-f0ad-3728c45c5985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CAREERFORGE AI - COMPLETE DEMO\n",
            "================================================================================\n",
            "✅ CareerForge AI System initialized with 5 agents\n",
            "\n",
            "🔍 Step 1/5: Searching for jobs...\n",
            "SerpAPI top keys: ['search_metadata', 'search_parameters', 'filters', 'jobs_results', 'serpapi_pagination']\n",
            "SerpAPI returned 10 job(s) after parsing.\n",
            "\n",
            " Initial fetch: 10 jobs\n",
            "  Entry Level AI Software Engineer                   Score: 55/100\n",
            "  AI Software Engineer (junior career, hybrid, Secre Score: 65/100\n",
            "  Robotics  AI Engineer  Entry Level                 Score: 62/100\n",
            "  Data-Driven AI/ML Technology Solutions Engineer (E Score: 55/100\n",
            "  Entry Level Hire  Remote Technical Support - AI an Score: 50/100\n",
            "  AI-Driven .NET Software Engineer — Entry Level     Score: 60/100\n",
            "  AI Engineer - Entry Level, Part-Time               Score: 64/100\n",
            "  Associate AI Engineer                              Score: 60/100\n",
            "  Innovation Intern - AI Engineering                 Score: 60/100\n",
            "  Entry to Mid-Level Agentic AI Engineer             Score: 60/100\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS: 5 jobs\n",
            "============================================================\n",
            "1. AI Software Engineer (junior career, hybrid, Secret cleared) - Lockheed Martin Corporation\n",
            "   Score: 65/100\n",
            "   Reason: Strong match\n",
            "2. AI Engineer - Entry Level, Part-Time - Lockheed Martin\n",
            "   Score: 64/100\n",
            "   Reason: Good match • Very recent posting\n",
            "3. Robotics  AI Engineer  Entry Level - Tata Consultancy Services\n",
            "   Score: 62/100\n",
            "   Reason: Good match • Very recent posting\n",
            "4. AI-Driven .NET Software Engineer — Entry Level - Midcontinent\n",
            "   Score: 60/100\n",
            "   Reason: Good match • Very recent posting\n",
            "5. Associate AI Engineer - Ascend Learning\n",
            "   Score: 60/100\n",
            "   Reason: Good match • Very recent posting\n",
            "\n",
            "✅ Returning 5 jobs (from 5 total)\n",
            "📝 Step 2/5: Tailoring resume...\n",
            "🎯 Step 3/5: Scoring ATS compatibility...\n",
            "💼 Step 4/5: Preparing interview materials...\n",
            "💰 Step 5/5: Creating negotiation strategy...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "WORKFLOW COMPLETE\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "JOB SEARCH\n",
            "================================================================================\n",
            "  [1] {'title': 'AI Software Engineer (junior career, hybrid, Secret cleared)', 'company': 'Lockheed Martin Corporation', 'location': 'Anywhere', 'url': 'https://www.tealhq.com/job/ai-software-engineer_7ea1a81a9ae4fa920ee43b4c797bd570d454b?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_me...\n",
            "  [2] {'title': 'AI Engineer - Entry Level, Part-Time', 'company': 'Lockheed Martin', 'location': 'Sunnyvale, CA', 'url': 'https://www.tealhq.com/job/ai-engineer-entry-level-part-time_2d7f15ef-5fe2-490c-adc2-eefba780bdde?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'pos...\n",
            "  [3] {'title': 'Robotics  AI Engineer  Entry Level', 'company': 'Tata Consultancy Services', 'location': 'Mountain View, CA', 'url': 'https://www.wayup.com/i-Information-Technology-and-Services-j-Robotics-AI-Engineer-Entry-Level-Tata-Consultancy-Services-202496426442010/?utm_campaign=google_jobs_apply&ut...\n",
            "  [4] {'title': 'AI-Driven .NET Software Engineer — Entry Level', 'company': 'Midcontinent', 'location': 'Sioux Falls, SD', 'url': 'https://www.learn4good.com/jobs/sioux-falls/south-dakota/software_development/4645176998/e/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', '...\n",
            "  [5] {'title': 'Associate AI Engineer', 'company': 'Ascend Learning', 'location': 'Leawood, KS', 'url': 'https://www.ziprecruiter.com/c/Ascend-Learning/Job/Associate-AI-Engineer/-in-Leawood,KS?jid=19c9aa79c6c688ec&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'posted_ho...\n",
            "\n",
            "================================================================================\n",
            "TAILORED RESUME\n",
            "================================================================================\n",
            "  • raw: ```json\n",
            "{\n",
            "  \"suggested_changes\": [\n",
            "    \"[SUGGESTED] Proficient in Python, SQL, and JavaScript.\",\n",
            "    \"[SUGGESTED] Expert in PyTorch, TensorFlow, scikit-learn, XGBoost, and HuggingFace Transformers.\",\n",
            "    \"[SUGGESTED] Hands-on experience with LLM Fine-tuning, Prompt Engineering, RAG, and Vector Datab...\n",
            "\n",
            "================================================================================\n",
            "ATS ANALYSIS\n",
            "================================================================================\n",
            "```json\n",
            "{\n",
            "  \"overall_score\": 76.2,\n",
            "  \"missing_skills\": [\n",
            "    \"develop\",\n",
            "    \"large\",\n",
            "    \"applications\",\n",
            "    \"language\",\n",
            "    \"apis\",\n",
            "    \"frameworks\",\n",
            "    \"deploy\",\n",
            "    \"training\",\n",
            "    \"systems\",\n",
            "    \"workflows\"\n",
            "  ],\n",
            "  \"recommended_changes\": [\n",
            "    \"Add 'Develop' to the summary: AI/ML Engineer with strong experience designing, training, and deploying machine learning and LLM-based systems. Adept at developing...\",\n",
            "    \"In the experience section for Machine Learning Engineer at TechNova AI, change 'Created REST API microservices for inference with <120ms latency at scale.' to 'Developed REST API microservices for inference with <120ms latency at scale using industry standard frameworks.'\",\n",
            "    \"In the experience section for AI Engineer Intern at CloudWorks Intelligence, change 'Built automated ETL workflows using Airflow for training data pipelines.' to 'Built automated ETL workflows using Airflow for training data pipelines to train large language models.'\",\n",
            "    \"In the Technical Skills...\n",
            "\n",
            "================================================================================\n",
            "INTERVIEW PREP\n",
            "================================================================================\n",
            "```json\n",
            "{\n",
            "  \"technical_questions\": [\n",
            "    {\n",
            "      \"question\": \"Describe your experience with deploying and managing AI/ML models on cloud platforms like Azure, AWS, or GCP. What are some challenges you've faced, and how did you overcome them?\",\n",
            "      \"why_asked\": \"This question assesses the candidate's hands-on experience with cloud deployment, a critical aspect of the role. It reveals their practical skills in managing scalability and reliability.\",\n",
            "      \"key_points\": [\n",
            "        \"Specific cloud platforms used (Azure, AWS, GCP).\",\n",
            "        \"Deployment tools and strategies.\",\n",
            "        \"Scalability and reliability considerations.\",\n",
            "        \"Troubleshooting and problem-solving skills.\",\n",
            "        \"Experience with MLOps practices.\"\n",
            "      ],\n",
            "      \"example_answer\": \"In my previous role, I deployed a fraud detection model on AWS SageMaker. We used Docker containers for consistent deployment and implemented auto-scaling to handle varying transaction volumes. One challenge was monitoring model perf...\n",
            "\n",
            "================================================================================\n",
            "SALARY STRATEGY\n",
            "================================================================================\n",
            "  • target_range: $111k-$150k\n",
            "  • counter_offer: 150000\n",
            "  • fallback_offer: 130000\n",
            "  • walk_away_point: 115000\n",
            "  • confidence: 0.75\n",
            "  • conversation_scripts: [\"I'm excited about the opportunity, but given my transferable skills and the market value for AI Engineers in San Francisco, I was expecting a salary in the range of $145k-$150k.\", 'While I understand this is a career transition, my previous experience provides a strong foundation for me to quickly...\n",
            "  • reasoning: The target salary is $130,625 based on an entry-level AI Engineer role in San Francisco, CA, considering it's a career transition with no relevant experience. I've set the counter offer at the high end of the market range and the walk-away point slightly below the calculated target to allow for some...\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "Successful steps: 5\n",
            "Failed steps: 0\n"
          ]
        }
      ],
      "source": [
        "async def run_demo():\n",
        "    \"\"\"\n",
        "    Main demo function that orchestrates the complete CareerForge workflow.\n",
        "    Returns dict with results from all 5 agents.\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"CAREERFORGE AI - COMPLETE DEMO\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Initialize system\n",
        "    try:\n",
        "        system = CareerForgeSystem()\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR constructing CareerForgeSystem: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return {\"error\": \"CareerForgeSystem initialization failed\", \"trace\": traceback.format_exc()}\n",
        "\n",
        "    # Verify workflow method exists\n",
        "    workflow_fn = getattr(system, \"run_full_workflow\", None)\n",
        "    if workflow_fn is None:\n",
        "        print(\"CareerForgeSystem has no 'run_full_workflow' method.\")\n",
        "        return {\"error\": \"Missing run_full_workflow\"}\n",
        "\n",
        "    # Prepare inputs\n",
        "    kwargs = {\n",
        "        \"resume\": SAMPLE_RESUME_BEFORE,\n",
        "        \"target_position\": \"AI Engineer\",\n",
        "        \"job_description\": SAMPLE_JOB,\n",
        "        \"company_name\": \"Capgemini Engineering\",\n",
        "    }\n",
        "\n",
        "    # Execute workflow\n",
        "    try:\n",
        "        if inspect.iscoroutinefunction(workflow_fn):\n",
        "            results = await asyncio.wait_for(workflow_fn(**kwargs), timeout=300)  # 5 min timeout\n",
        "        else:\n",
        "            loop = asyncio.get_running_loop()\n",
        "            results = await loop.run_in_executor(None, lambda: workflow_fn(**kwargs))\n",
        "    except asyncio.TimeoutError:\n",
        "        print(\"ERROR: Workflow timed out after 5 minutes\")\n",
        "        return {\"error\": \"Workflow timeout\"}\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR running workflow: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return {\"error\": \"Workflow execution failed\", \"trace\": traceback.format_exc()}\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(\"WORKFLOW COMPLETE\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    if not results:\n",
        "        print(\"No results returned.\")\n",
        "        return results\n",
        "\n",
        "    for key, value in results.items():\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"{key.upper().replace('_', ' ')}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if isinstance(value, dict):\n",
        "            for k, v in value.items():\n",
        "                s = str(v)\n",
        "                print(f\"  • {k}: {s[:300]}{'...' if len(s) > 300 else ''}\")\n",
        "        elif isinstance(value, (list, tuple)):\n",
        "            for i, item in enumerate(value):\n",
        "                s = str(item)\n",
        "                print(f\"  [{i+1}] {s[:300]}{'...' if len(s) > 300 else ''}\")\n",
        "        else:\n",
        "            s = str(value)\n",
        "            max_len = 1000 if \"error\" not in key.lower() else 500\n",
        "            print(s[:max_len] + (\"...\" if len(s) > max_len else \"\"))\n",
        "\n",
        "    # Summary statistics\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    success_count = sum(1 for k in results.keys() if \"error\" not in k)\n",
        "    error_count = sum(1 for k in results.keys() if \"error\" in k)\n",
        "    print(f\"Successful steps: {success_count}\")\n",
        "    print(f\"Failed steps: {error_count}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "result = await run_demo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2DeEo79YWxz",
        "outputId": "c622d904-3d60-4815-a6d9-93263b53ea82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================================================================================================\n",
            "                  🚀 CAREERFORGE AI - COMPLETE ANALYSIS REPORT                   \n",
            "                         Generated: 2025-11-29 01:49:41                         \n",
            "================================================================================================================================================================\n",
            "\n",
            "================================================================================================================================================================\n",
            "                              🔍 JOB SEARCH RESULTS                              \n",
            "================================================================================================================================================================\n",
            "\n",
            "📊 Found 5 matching positions\n",
            "\n",
            "┌─ Job #1 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "│ 📌 AI Software Developer- Healthcare Domain- Visa Independent\n",
            "│ 🏢 Shrive Technologies\n",
            "│ 📍 United States\n",
            "│ 💰 Salary: Not specified\n",
            "│ ⏰ Posted: 1 day ago\n",
            "│ ⭐ Match Score: 74/100\n",
            "│ ✅ Why it matches:\n",
            "│    Strong match • skills: Python, Go • Very recent posting\n",
            "│ 🔗 Apply: https://www.linkedin.com/jobs/view/ai-software-developer-healthcare-domain-visa-independent-at-shrive-technologies-4339257143?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
            "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "┌─ Job #2 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "│ 📌 NIKE, Inc. Innovation AI & Machine Learning Graduate Intern\n",
            "│ 🏢 Nike\n",
            "│ 📍 Anywhere\n",
            "│ 💰 Salary: Not specified\n",
            "│ ⏰ Posted: Recent\n",
            "│ ⭐ Match Score: 70/100\n",
            "│ ✅ Why it matches:\n",
            "│    Strong match • Very recent posting\n",
            "│ 🔗 Apply: https://careers.nike.com/nike-inc-innovation-ai-machine-learning-graduate-intern/job/R-72699?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
            "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "┌─ Job #3 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "│ 📌 Moveworks Conversational AI Engineer\n",
            "│ 🏢 Acunor\n",
            "│ 📍 California (+1 other)\n",
            "│ 💰 Salary: Not specified\n",
            "│ ⏰ Posted: 2 days ago\n",
            "│ ⭐ Match Score: 67/100\n",
            "│ ✅ Why it matches:\n",
            "│    Strong match • skills: Python • Very recent posting\n",
            "│ 🔗 Apply: https://www.talent.com/view?id=6d19b63aa697&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
            "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "┌─ Job #4 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "│ 📌 AI Data Engineer\n",
            "│ 🏢 Citadel\n",
            "│ 📍 New York, NY\n",
            "│ 💰 Salary: $150,000 \n",
            "│ ⏰ Posted: 1 day ago\n",
            "│ ⭐ Match Score: 63/100\n",
            "│ ✅ Why it matches:\n",
            "│    Good match • skills: Go • Very recent posting\n",
            "│ 🔗 Apply: https://www.citadelsecurities.com/careers/details/ai-data-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
            "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "┌─ Job #5 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "│ 📌 AI Engineer, United States - BCG X\n",
            "│ 🏢 Boston Consulting Group\n",
            "│ 📍 Seattle, WA (+10 others)\n",
            "│ 💰 Salary: $10 \n",
            "│ ⏰ Posted: 2 days ago\n",
            "│ ⭐ Match Score: 63/100\n",
            "│ ✅ Why it matches:\n",
            "│    Good match • skills: Go • Very recent posting\n",
            "│ 🔗 Apply: https://careers.bcg.com/global/en/job/55995/AI-Engineer-United-States-BCG-X?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
            "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "💾 Saved to: /mnt/data/careerforge_outputs/job_search_20251129_014941.json\n",
            "\n",
            "================================================================================================================================================================\n",
            "                               📝 TAILORED RESUME                                \n",
            "================================================================================================================================================================\n",
            "\n",
            "\n",
            "💾 Saved to: /mnt/data/careerforge_outputs/tailored_resume_20251129_014941.json\n",
            "\n",
            "================================================================================================================================================================\n",
            "                          🎯 ATS COMPATIBILITY ANALYSIS                          \n",
            "================================================================================================================================================================\n",
            "\n",
            "🟢 Overall ATS Score: 81.2/100\n",
            "\n",
            "⚠️  Missing Keywords (10 total):\n",
            "\n",
            "  develop            | large              | azure              | language          \n",
            "  deploy             | apis               | frameworks         | training          \n",
            "  systems            | workflows         \n",
            "\n",
            "💡 Recommendations (4 changes):\n",
            "\n",
            "1.    Add 'Developed and deployed machine learning models and AI-powered\n",
            "   applications' to the summary.\n",
            "\n",
            "2.    Incorporate 'Azure' into the Technical Skills section under Cloud\n",
            "   Platforms alongside AWS and GCP.\n",
            "\n",
            "3.    Add 'Experience developing REST APIs for integrating AI models into\n",
            "   systems' to the summary.\n",
            "\n",
            "4.    Include 'Experience with large language models and transformer frameworks'\n",
            "   in the Technical Skills section, potentially under AI Tools.\n",
            "\n",
            "💾 Saved to: /mnt/data/careerforge_outputs/ats_analysis_20251129_014941.json\n",
            "\n",
            "================================================================================================================================================================\n",
            "                            💼 INTERVIEW PREPARATION                             \n",
            "================================================================================================================================================================\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "  🔧 Technical Questions\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 1/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Explain the differences between TensorFlow and PyTorch, and describe a scenario where you would prefer one over the other for developing and deploying AI/ML models.\n",
            "\n",
            "📌 Why they ask this:\n",
            "   Tests the candidate's depth of understanding and practical experience\n",
            "   with popular ML frameworks.\n",
            "\n",
            "🎯 Key points to cover:\n",
            "   • Key architectural differences (e.g., dynamic vs. static computation graphs).\n",
            "   • Ease of use and debugging.\n",
            "   • Community support and ecosystem.\n",
            "   • Performance considerations for specific tasks.\n",
            "   • Deployment challenges and solutions.\n",
            "\n",
            "💬 Example answer:\n",
            "   TensorFlow uses a static computation graph, which can be more\n",
            "   efficient for production deployment but harder to debug. PyTorch uses\n",
            "   a dynamic graph, which offers more flexibility and easier debugging\n",
            "   during research and development. I'd prefer TensorFlow for deploying\n",
            "   large-scale models due to its optimization capabilities and PyTorch\n",
            "   for rapid prototyping and experimentation.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 2/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Describe the architecture of a transformer model and explain how it is used in Large Language Models (LLMs).\n",
            "\n",
            "📌 Why they ask this:\n",
            "   Assesses understanding of fundamental concepts behind LLMs.\n",
            "\n",
            "🎯 Key points to cover:\n",
            "   • Attention mechanism and its role.\n",
            "   • Encoder-decoder structure.\n",
            "   • Self-attention and multi-head attention.\n",
            "   • Application to sequence-to-sequence tasks.\n",
            "   • How transformers capture long-range dependencies.\n",
            "\n",
            "💬 Example answer:\n",
            "   Transformer models are based on the attention mechanism, which allows\n",
            "   the model to weigh the importance of different parts of the input\n",
            "   sequence. They consist of encoder and decoder layers, with\n",
            "   self-attention enabling the model to capture long-range dependencies.\n",
            "   In LLMs, transformers are used to predict the next word in a sequence,\n",
            "   enabling the generation of coherent and contextually relevant text.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 3/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Explain the concept of Retrieval-Augmented Generation (RAG) and how it improves the performance of Large Language Models. Describe a project where you implemented RAG.\n",
            "\n",
            "📌 Why they ask this:\n",
            "   Tests knowledge of advanced techniques for enhancing LLM performance\n",
            "   and practical implementation experience.\n",
            "\n",
            "🎯 Key points to cover:\n",
            "   • How RAG combines retrieval and generation.\n",
            "   • The role of vector databases in RAG.\n",
            "   • Benefits of RAG (e.g., reduced hallucinations, improved accuracy).\n",
            "   • Challenges in implementing RAG (e.g., retrieval quality, latency).\n",
            "   • Specific project details and outcomes.\n",
            "\n",
            "💬 Example answer:\n",
            "   RAG enhances LLMs by retrieving relevant information from a knowledge\n",
            "   source and using it to augment the generation process. Vector\n",
            "   databases store and retrieve information based on semantic similarity.\n",
            "   RAG reduces hallucinations and improves accuracy by grounding the\n",
            "   LLM's responses in factual knowledge. In a recent project, I\n",
            "   implemented a RAG system using Faiss and LangChain to improve the\n",
            "   accuracy of a customer support chatbot.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 4/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Describe your experience with deploying AI/ML models on cloud platforms like Azure, AWS, or GCP. What are some of the challenges you faced, and how did you address them?\n",
            "\n",
            "📌 Why they ask this:\n",
            "   Evaluates practical skills in deploying and managing models in\n",
            "   production environments.\n",
            "\n",
            "🎯 Key points to cover:\n",
            "   • Specific cloud platforms and services used.\n",
            "   • Deployment strategies (e.g., containerization, serverless).\n",
            "   • Scalability and reliability considerations.\n",
            "   • Monitoring and logging practices.\n",
            "   • Cost optimization techniques.\n",
            "\n",
            "💬 Example answer:\n",
            "   I have experience deploying models on AWS SageMaker using\n",
            "   containerization with Docker. Some challenges I faced included\n",
            "   ensuring scalability and optimizing inference times. I addressed these\n",
            "   by using auto-scaling policies, optimizing model code, and leveraging\n",
            "   GPU instances for computationally intensive tasks. Monitoring was\n",
            "   implemented using CloudWatch to track performance metrics and identify\n",
            "   potential issues.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 5/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Explain the importance of prompt engineering and describe different techniques you have used to improve the performance of LLMs.\n",
            "\n",
            "📌 Why they ask this:\n",
            "   Tests understanding of how to effectively interact with and control\n",
            "   LLMs.\n",
            "\n",
            "🎯 Key points to cover:\n",
            "   • The impact of prompt design on LLM outputs.\n",
            "   • Different prompt engineering techniques (e.g., few-shot learning, chain-of-thought).\n",
            "   • Strategies for mitigating biases and improving accuracy.\n",
            "   • Examples of successful prompt designs.\n",
            "   • Iterative refinement of prompts based on performance.\n",
            "\n",
            "💬 Example answer:\n",
            "   Prompt engineering is crucial for guiding LLMs to generate desired\n",
            "   outputs. Techniques like few-shot learning, where a few examples are\n",
            "   provided in the prompt, and chain-of-thought prompting, where the\n",
            "   model is encouraged to explain its reasoning, can significantly\n",
            "   improve performance. I've used these techniques to reduce biases and\n",
            "   increase the accuracy of LLM-generated content by carefully crafting\n",
            "   prompts and iteratively refining them based on results.\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "  🤝 Behavioral Questions (STAR Method)\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 1/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Describe a time when you had to collaborate with a cross-functional team to deliver an AI/ML project. What were the challenges, and how did you overcome them?\n",
            "\n",
            "💡 Tips:\n",
            "   ['Specific roles and responsibilities of team members.',\n",
            "   'Communication strategies used.', 'Conflict resolution techniques.',\n",
            "   'How you ensured alignment on project goals.', 'Positive outcomes of\n",
            "   the collaboration.']\n",
            "\n",
            "💬 Example (STAR format):\n",
            "   In a recent project, I collaborated with data scientists, software\n",
            "   engineers, and business stakeholders. A challenge was aligning\n",
            "   technical solutions with business requirements. We overcame this by\n",
            "   holding regular meetings, creating detailed documentation, and using\n",
            "   iterative feedback loops to ensure everyone was on the same page. The\n",
            "   result was a successful deployment that met all business objectives.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 2/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Tell me about a time when you had to learn a new AI/ML technique or technology quickly. What steps did you take, and what was the outcome?\n",
            "\n",
            "💡 Tips:\n",
            "   ['The specific technology or technique.', 'The resources you used for\n",
            "   learning.', 'Your learning process and timeline.', 'How you applied\n",
            "   the new knowledge to solve a problem.', 'Lessons learned and future\n",
            "   applications.']\n",
            "\n",
            "💬 Example (STAR format):\n",
            "   I needed to learn about LangChain quickly for a project involving\n",
            "   LLM-based chatbot development. I started by reading the documentation,\n",
            "   watching online tutorials, and experimenting with sample code. Within\n",
            "   a week, I was able to use LangChain to build a prototype chatbot that\n",
            "   integrated with our existing data sources. This experience taught me\n",
            "   the importance of hands-on practice and continuous learning.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 3/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Describe a situation where you identified a significant problem in an existing AI/ML system and proposed a solution. What was the problem, your solution, and the results?\n",
            "\n",
            "💡 Tips:\n",
            "   ['The specific problem and its impact.', 'Your analysis of the root\n",
            "   cause.', 'The proposed solution and its rationale.', 'Implementation\n",
            "   details and challenges.', 'Quantifiable results and improvements.']\n",
            "\n",
            "💬 Example (STAR format):\n",
            "   I noticed that our model's inference times were increasing due to\n",
            "   inefficient data preprocessing. I proposed optimizing the data\n",
            "   pipeline using vectorization techniques. After implementing the\n",
            "   changes, we reduced inference times by 30%, resulting in a significant\n",
            "   improvement in system performance and user experience.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 4/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Tell me about a time when you had to present complex AI/ML concepts to a non-technical audience. How did you ensure they understood the information?\n",
            "\n",
            "💡 Tips:\n",
            "   ['The specific concepts you presented.', \"The audience's background\n",
            "   and level of understanding.\", 'The strategies you used to simplify the\n",
            "   information.', 'Visual aids and analogies used.', 'Feedback received\n",
            "   and adjustments made.']\n",
            "\n",
            "💬 Example (STAR format):\n",
            "   I had to explain the concept of neural networks to a group of\n",
            "   marketing managers. I used analogies to explain how neural networks\n",
            "   learn patterns from data, comparing it to how the human brain makes\n",
            "   associations. I avoided technical jargon and used visual aids to\n",
            "   illustrate the key concepts. By the end of the presentation, they had\n",
            "   a clear understanding of how neural networks could be used to improve\n",
            "   marketing campaigns.\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Question 5/5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "❓ Describe a time when you failed to meet a deadline or achieve a project goal. What did you learn from the experience, and how did you adjust your approach in subsequent projects?\n",
            "\n",
            "💡 Tips:\n",
            "   ['The specific project and the missed deadline or goal.', 'The\n",
            "   reasons for the failure.', 'Your reaction and response.', 'Lessons\n",
            "   learned and changes implemented.', 'Positive outcomes of the learning\n",
            "   experience.']\n",
            "\n",
            "💬 Example (STAR format):\n",
            "   In one project, I underestimated the time required for model\n",
            "   fine-tuning, leading to a missed deadline. I learned the importance of\n",
            "   breaking down tasks into smaller, more manageable steps and accurately\n",
            "   estimating the time required for each. In subsequent projects, I've\n",
            "   used project management tools to track progress and proactively\n",
            "   identify potential delays, allowing me to adjust the plan and meet\n",
            "   deadlines.\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "  🏢 Company Insights\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "• Capgemini Engineering is a global leader in engineering and R&D services.\n",
            "• They offer a wide range of services including digital engineering, product engineering, and sustainability solutions.\n",
            "• They serve various industries such as aerospace, automotive, energy, and healthcare.\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "  🗣️ Key Talking Points\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "✓ Capgemini's focus on innovation and digital transformation aligns with my passion for developing cutting-edge AI solutions.\n",
            "✓ Their commitment to sustainability resonates with my personal values and my interest in applying AI for environmental good.\n",
            "✓ I am excited about the opportunity to work on diverse projects across different industries and contribute to Capgemini's global impact.\n",
            "\n",
            "💾 Saved to: /mnt/data/careerforge_outputs/interview_prep_20251129_014941.json\n",
            "\n",
            "================================================================================================================================================================\n",
            "                         💰 SALARY NEGOTIATION STRATEGY                          \n",
            "================================================================================================================================================================\n",
            "\n",
            "📊 Market Analysis:\n",
            "\n",
            "   Target Range:  $111k-$150k\n",
            "\n",
            "💵 Negotiation Strategy:\n",
            "\n",
            "   🎯 Counter Offer:   $150,218\n",
            "   ⚖️  Fallback Offer:  $130,625\n",
            "   🚪 Walk-Away Point: $120,000\n",
            "   📈 Confidence:      75%\n",
            "\n",
            "💬 Conversation Scripts:\n",
            "\n",
            "1.    Based on my research and the market demand for AI Engineers in San\n",
            "   Francisco, I was expecting a salary in the range of $145,000 to $155,000.\n",
            "\n",
            "2.    While I am excited about this opportunity, I need to ensure that my\n",
            "   compensation reflects my skills and the cost of living in San Francisco.\n",
            "   Could we revisit the offer?\n",
            "\n",
            "3.    I understand this is a career transition for me, but I am a fast learner\n",
            "   and confident I can quickly contribute significantly to your team. I'm\n",
            "   looking for a salary that reflects my potential impact.\n",
            "\n",
            "📝 Strategy Reasoning:\n",
            "\n",
            "   The target salary is $130,625 based on an entry-level AI Engineer role in\n",
            "   San Francisco, CA, considering the career transition and 0 years of\n",
            "   relevant experience. The counter offer reflects the top of the market\n",
            "   range, while the fallback is the initial target.\n",
            "\n",
            "💾 Saved to: /mnt/data/careerforge_outputs/salary_strategy_20251129_014941.json\n"
          ]
        }
      ],
      "source": [
        "# Output Formatter\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from IPython.display import Markdown, display, HTML\n",
        "from datetime import datetime\n",
        "\n",
        "OUT_DIR = \"/mnt/data/careerforge_outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# HELPER FUNCTIONS\n",
        "\n",
        "def _try_parse(s):\n",
        "    \"\"\"Try to parse JSON from string or return as-is\"\"\"\n",
        "    if isinstance(s, (dict, list)):\n",
        "        return s\n",
        "    if not isinstance(s, str):\n",
        "        return None\n",
        "    s = s.strip()\n",
        "\n",
        "    # JSON parse\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Strip markdown code blocks\n",
        "    patterns = [\n",
        "        r\"```(?:json)?\\s*(\\{.*\\}|\\[.*\\])\\s*```\",\n",
        "        r\"```(?:json)?\\s*(.*?)\\s*```\",\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        m = re.search(pattern, s, flags=re.DOTALL)\n",
        "        if m:\n",
        "            try:\n",
        "                return json.loads(m.group(1))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def _save_file(key, obj, raw):\n",
        "    \"\"\"Save parsed JSON or raw text to file\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    if obj is not None:\n",
        "        path = os.path.join(OUT_DIR, f\"{key}_{timestamp}.json\")\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(obj, f, indent=2, ensure_ascii=False)\n",
        "    else:\n",
        "        path = os.path.join(OUT_DIR, f\"{key}_{timestamp}.txt\")\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(raw or \"\")\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "def _print_section_header(title, emoji=\"\"):\n",
        "    \"\"\"Print a beautiful section header\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 160)\n",
        "    print(f\"{emoji} {title}\".center(80) if emoji else title.center(80))\n",
        "    print(\"=\" * 160 + \"\\n\")\n",
        "\n",
        "\n",
        "def _print_subsection(title):\n",
        "    \"\"\"Print a subsection divider\"\"\"\n",
        "    print(\"\\n\" + \"-\" * 160)\n",
        "    print(f\"  {title}\")\n",
        "    print(\"-\" * 160 + \"\\n\")\n",
        "\n",
        "\n",
        "def _truncate(text, max_length=500, add_ellipsis=True):\n",
        "    \"\"\"Truncate text intelligently\"\"\"\n",
        "    if not text or len(str(text)) <= max_length:\n",
        "        return str(text)\n",
        "\n",
        "    truncated = str(text)[:max_length].rsplit(' ', 1)[0]\n",
        "    return truncated + \"...\" if add_ellipsis else truncated\n",
        "\n",
        "# SECTION FORMATTERS\n",
        "\n",
        "def format_job_search(result):\n",
        "    \"\"\"Format job search results\"\"\"\n",
        "    _print_section_header(\"JOB SEARCH RESULTS\", \"🔍\")\n",
        "\n",
        "    jobs_raw = result.get(\"job_search\") or result.get(\"job_search_error\")\n",
        "    jobs = _try_parse(jobs_raw)\n",
        "\n",
        "    # Handle nested structure\n",
        "    if isinstance(jobs, dict):\n",
        "        if \"job_matches\" in jobs:\n",
        "            jobs = jobs[\"job_matches\"]\n",
        "        elif \"top_matches\" in jobs:\n",
        "            jobs = jobs[\"top_matches\"]\n",
        "        elif \"jobs\" in jobs:\n",
        "            jobs = jobs[\"jobs\"]\n",
        "\n",
        "    if isinstance(jobs, list) and len(jobs) > 0:\n",
        "        print(f\"📊 Found {len(jobs)} matching positions\\n\")\n",
        "\n",
        "        for i, job in enumerate(jobs, 1):\n",
        "            title = job.get(\"title\") or job.get(\"job_title\") or \"Unknown Position\"\n",
        "            company = job.get(\"company\") or \"Unknown Company\"\n",
        "            location = job.get(\"location\") or \"Location not specified\"\n",
        "            posted = job.get(\"posted_time\") or job.get(\"posted_hours_ago\") or \"Recently\"\n",
        "            salary = job.get(\"salary_range\") or job.get(\"salary\") or \"Not specified\"\n",
        "            score = job.get(\"match_score\", \"\")\n",
        "            reason = job.get(\"match_reason\") or job.get(\"reason\") or \"\"\n",
        "            url = job.get(\"url\") or \"\"\n",
        "\n",
        "            print(f\"┌─ Job #{i} {'─' * 160}\")\n",
        "            print(f\"│ 📌 {title}\")\n",
        "            print(f\"│ 🏢 {company}\")\n",
        "            print(f\"│ 📍 {location}\")\n",
        "            print(f\"│ 💰 Salary: {salary}\")\n",
        "            print(f\"│ ⏰ Posted: {posted}\")\n",
        "\n",
        "            if score:\n",
        "                print(f\"│ ⭐ Match Score: {score}/100\")\n",
        "\n",
        "            if reason:\n",
        "                print(f\"│ ✅ Why it matches:\")\n",
        "                # Word wrap reason\n",
        "                for line in _wrap_text(reason, width=70):\n",
        "                    print(f\"│    {line}\")\n",
        "\n",
        "            if url:\n",
        "                print(f\"│ 🔗 Apply: {url}\")\n",
        "\n",
        "            print(f\"└{'─' * 160}\\n\")\n",
        "\n",
        "    else:\n",
        "        print(\"ℹ️  No jobs found or parsing failed\")\n",
        "        if isinstance(jobs_raw, str):\n",
        "            print(f\"\\nRaw output:\\n{jobs_raw[:500]}...\")\n",
        "\n",
        "    # Save to file\n",
        "    path = _save_file(\"job_search\", jobs, str(jobs_raw))\n",
        "    print(f\"💾 Saved to: {path}\")\n",
        "\n",
        "\n",
        "def format_tailored_resume(result):\n",
        "    \"\"\"Format tailored resume\"\"\"\n",
        "    _print_section_header(\"TAILORED RESUME\", \"📝\")\n",
        "\n",
        "    tailored_raw = result.get(\"tailored_resume\") or result.get(\"tailored_resume_error\") or \"\"\n",
        "    tailored = _try_parse(tailored_raw)\n",
        "\n",
        "    if isinstance(tailored, dict):\n",
        "        # Handle structured resume\n",
        "        suggested = tailored.get(\"suggested_changes\") or []\n",
        "        optimized = tailored.get(\"optimized_resume\") or tailored.get(\"resume\") or \"\"\n",
        "\n",
        "        if suggested:\n",
        "            print(\"🎯 Suggested Changes:\\n\")\n",
        "            for i, change in enumerate(suggested, 1):\n",
        "                print(f\"{i}. {change}\\n\")\n",
        "\n",
        "        if optimized:\n",
        "            print(\"\\n📄 Optimized Resume:\\n\")\n",
        "            print(optimized)\n",
        "\n",
        "    elif isinstance(tailored_raw, str) and len(tailored_raw) > 100:\n",
        "        # Markdown resume\n",
        "        print(\"📄 Full Resume (Markdown):\\n\")\n",
        "        display(Markdown(tailored_raw))\n",
        "\n",
        "    else:\n",
        "        print(\"ℹ️  No resume data or parsing failed\")\n",
        "        print(f\"\\nRaw output:\\n{str(tailored_raw)[:500]}...\")\n",
        "\n",
        "    # Save to file\n",
        "    path = _save_file(\"tailored_resume\", tailored, str(tailored_raw))\n",
        "    print(f\"\\n💾 Saved to: {path}\")\n",
        "\n",
        "\n",
        "def format_ats_analysis(result):\n",
        "    \"\"\"Format ATS analysis\"\"\"\n",
        "    _print_section_header(\"ATS COMPATIBILITY ANALYSIS\", \"🎯\")\n",
        "\n",
        "    ats_raw = result.get(\"ats_analysis\") or result.get(\"ats_analysis_error\")\n",
        "    ats = _try_parse(ats_raw)\n",
        "\n",
        "    if isinstance(ats, dict):\n",
        "        # Overall score\n",
        "        overall = ats.get(\"overall_score\") or ats.get(\"overall\") or ats.get(\"score\")\n",
        "        if overall:\n",
        "            score_val = float(overall)\n",
        "            emoji = \"🟢\" if score_val >= 80 else \"🟡\" if score_val >= 60 else \"🔴\"\n",
        "            print(f\"{emoji} Overall ATS Score: {overall}/100\\n\")\n",
        "\n",
        "        # Score breakdown\n",
        "        breakdown = ats.get(\"breakdown\") or {}\n",
        "        if breakdown:\n",
        "            print(\"📊 Score Breakdown:\\n\")\n",
        "            for category, score in breakdown.items():\n",
        "                bar = \"█\" * int(float(score) / 5) + \"░\" * (20 - int(float(score) / 5))\n",
        "                print(f\"  {category:20s} [{bar}] {score}/100\")\n",
        "            print()\n",
        "\n",
        "        # Missing skills\n",
        "        missing = ats.get(\"missing_skills\") or ats.get(\"missing\") or []\n",
        "        if missing:\n",
        "            print(f\"⚠️  Missing Keywords ({len(missing)} total):\\n\")\n",
        "            for i in range(0, len(missing[:20]), 4):\n",
        "                row = missing[i:i+4]\n",
        "                print(\"  \" + \" | \".join(f\"{skill:18s}\" for skill in row))\n",
        "            if len(missing) > 20:\n",
        "                print(f\"\\n  ... and {len(missing) - 20} more\")\n",
        "            print()\n",
        "\n",
        "        # Recommendations\n",
        "        recs = ats.get(\"recommended_changes\") or ats.get(\"suggestions\") or []\n",
        "        if recs:\n",
        "            print(f\"💡 Recommendations ({len(recs)} changes):\\n\")\n",
        "            for i, rec in enumerate(recs, 1):\n",
        "                if isinstance(rec, str):\n",
        "                    text = rec\n",
        "                elif isinstance(rec, dict):\n",
        "                    text = rec.get(\"text\") or rec.get(\"change\") or rec.get(\"suggestion\") or json.dumps(rec)\n",
        "                else:\n",
        "                    text = str(rec)\n",
        "\n",
        "                # Word wrap\n",
        "                print(f\"{i}. \", end=\"\")\n",
        "                for line in _wrap_text(text, width=75):\n",
        "                    print(f\"   {line}\")\n",
        "                print()\n",
        "\n",
        "    else:\n",
        "        print(\"ℹ️  No ATS data or parsing failed\")\n",
        "        print(f\"\\nRaw output:\\n{str(ats_raw)[:500]}...\")\n",
        "\n",
        "    # Save to file\n",
        "    path = _save_file(\"ats_analysis\", ats, str(ats_raw))\n",
        "    print(f\"💾 Saved to: {path}\")\n",
        "\n",
        "\n",
        "def format_interview_prep(result):\n",
        "    \"\"\"Format interview prep materials\"\"\"\n",
        "    _print_section_header(\"INTERVIEW PREPARATION\", \"💼\")\n",
        "\n",
        "    ip_raw = result.get(\"interview_prep\") or result.get(\"interview_prep_error\")\n",
        "    ip = _try_parse(ip_raw)\n",
        "\n",
        "    if isinstance(ip, dict):\n",
        "        # Technical questions\n",
        "        tqs = ip.get(\"technical_questions\") or ip.get(\"technical\") or []\n",
        "        if tqs:\n",
        "            _print_subsection(\"🔧 Technical Questions\")\n",
        "\n",
        "            for i, q in enumerate(tqs, 1):\n",
        "                print(f\"\\n{'─' * 160}\")\n",
        "                print(f\"Question {i}/{len(tqs)}\")\n",
        "                print('─' * 160)\n",
        "\n",
        "                if isinstance(q, dict):\n",
        "                    question = q.get(\"question\") or \"\"\n",
        "                    why = q.get(\"why_asked\") or q.get(\"why\") or \"\"\n",
        "                    key_points = q.get(\"key_points\") or q.get(\"key_points_to_cover\") or \"\"\n",
        "                    example = q.get(\"example_answer\") or q.get(\"example\") or \"\"\n",
        "\n",
        "                    print(f\"\\n❓ {question}\\n\")\n",
        "\n",
        "                    if why:\n",
        "                        print(f\"📌 Why they ask this:\")\n",
        "                        for line in _wrap_text(why, width=70):\n",
        "                            print(f\"   {line}\")\n",
        "                        print()\n",
        "\n",
        "                    if key_points:\n",
        "                        print(f\"🎯 Key points to cover:\")\n",
        "                        if isinstance(key_points, list):\n",
        "                            for point in key_points:\n",
        "                                print(f\"   • {point}\")\n",
        "                        else:\n",
        "                            for line in str(key_points).split(\"\\n\"):\n",
        "                                if line.strip():\n",
        "                                    print(f\"   • {line.strip()}\")\n",
        "                        print()\n",
        "\n",
        "                    if example:\n",
        "                        print(f\"💬 Example answer:\")\n",
        "                        for line in _wrap_text(example, width=70):\n",
        "                            print(f\"   {line}\")\n",
        "                        print()\n",
        "                else:\n",
        "                    print(f\"\\n❓ {str(q)}\\n\")\n",
        "\n",
        "        # Behavioral questions\n",
        "        bqs = ip.get(\"behavioral_questions\") or ip.get(\"behavioral\") or []\n",
        "        if bqs:\n",
        "            _print_subsection(\"🤝 Behavioral Questions (STAR Method)\")\n",
        "\n",
        "            for i, q in enumerate(bqs, 1):\n",
        "                print(f\"\\n{'─' * 160}\")\n",
        "                print(f\"Question {i}/{len(bqs)}\")\n",
        "                print('─' * 160)\n",
        "\n",
        "                if isinstance(q, dict):\n",
        "                    question = q.get(\"question\") or \"\"\n",
        "                    tips = q.get(\"key_points\") or q.get(\"tips\") or \"\"\n",
        "                    example = q.get(\"example_answer\") or q.get(\"example\") or \"\"\n",
        "\n",
        "                    print(f\"\\n❓ {question}\\n\")\n",
        "\n",
        "                    if tips:\n",
        "                        print(f\"💡 Tips:\")\n",
        "                        for line in _wrap_text(tips, width=70):\n",
        "                            print(f\"   {line}\")\n",
        "                        print()\n",
        "\n",
        "                    if example:\n",
        "                        print(f\"💬 Example (STAR format):\")\n",
        "                        for line in _wrap_text(example, width=70):\n",
        "                            print(f\"   {line}\")\n",
        "                        print()\n",
        "                else:\n",
        "                    print(f\"\\n❓ {str(q)}\\n\")\n",
        "\n",
        "        # Company insights\n",
        "        insights = ip.get(\"company_insights\") or []\n",
        "        if insights:\n",
        "            _print_subsection(\"🏢 Company Insights\")\n",
        "            if isinstance(insights, str):\n",
        "                print(f\"• {insights}\")\n",
        "            elif isinstance(insights, list):\n",
        "                for insight in insights:\n",
        "                    if isinstance(insight, str):\n",
        "                        print(f\"• {insight}\")\n",
        "                    else:\n",
        "                        print(f\"• {str(insight)}\")\n",
        "            print()\n",
        "\n",
        "        # Talking points\n",
        "        talking_points = ip.get(\"talking_points\") or []\n",
        "        if talking_points:\n",
        "            _print_subsection(\"🗣️ Key Talking Points\")\n",
        "            if isinstance(talking_points, str):\n",
        "                print(f\"✓ {talking_points}\")\n",
        "            elif isinstance(talking_points, list):\n",
        "                for point in talking_points:\n",
        "                    if isinstance(point, str):\n",
        "                        print(f\"✓ {point}\")\n",
        "                    else:\n",
        "                        print(f\"✓ {str(point)}\")\n",
        "            print()\n",
        "\n",
        "    else:\n",
        "        print(\"ℹ️  No interview prep data or parsing failed\")\n",
        "        print(f\"\\nRaw output:\\n{str(ip_raw)[:500]}...\")\n",
        "\n",
        "    # Save to file\n",
        "    path = _save_file(\"interview_prep\", ip, str(ip_raw))\n",
        "    print(f\"💾 Saved to: {path}\")\n",
        "\n",
        "\n",
        "def format_salary_strategy(result):\n",
        "    \"\"\"Format salary negotiation strategy\"\"\"\n",
        "    _print_section_header(\"SALARY NEGOTIATION STRATEGY\", \"💰\")\n",
        "\n",
        "    sal_raw = (\n",
        "        result.get(\"salary_strategy\") or\n",
        "        result.get(\"salary_strategy_error\") or\n",
        "        result.get(\"negotiation_strategy\")\n",
        "    )\n",
        "    sal = _try_parse(sal_raw)\n",
        "\n",
        "    # Handle nested structure\n",
        "    if isinstance(sal, dict) and \"negotiation_strategy\" in sal:\n",
        "        analysis = sal.get(\"analysis\", {})\n",
        "        sal = sal[\"negotiation_strategy\"]\n",
        "    else:\n",
        "        analysis = {}\n",
        "\n",
        "    if isinstance(sal, dict):\n",
        "        # Market data\n",
        "        target_range = sal.get(\"target_range\") or analysis.get(\"market_range\")\n",
        "        market_median = analysis.get(\"market_median\")\n",
        "\n",
        "        print(\"📊 Market Analysis:\\n\")\n",
        "        if market_median:\n",
        "            print(f\"   Market Median: ${market_median:,}\")\n",
        "        if target_range:\n",
        "            if isinstance(target_range, str):\n",
        "                print(f\"   Target Range:  {target_range}\")\n",
        "            else:\n",
        "                print(f\"   Target Range:  ${target_range[0]:,} - ${target_range[1]:,}\")\n",
        "        print()\n",
        "\n",
        "        # Negotiation numbers\n",
        "        print(\"💵 Negotiation Strategy:\\n\")\n",
        "        counter = sal.get(\"counter_offer\")\n",
        "        fallback = sal.get(\"fallback_offer\") or sal.get(\"fallback\")\n",
        "        walk_away = sal.get(\"walk_away_point\")\n",
        "        confidence = sal.get(\"confidence\")\n",
        "\n",
        "        if counter:\n",
        "            print(f\"   🎯 Counter Offer:   ${counter:,}\")\n",
        "        if fallback:\n",
        "            print(f\"   ⚖️  Fallback Offer:  ${fallback:,}\")\n",
        "        if walk_away:\n",
        "            print(f\"   🚪 Walk-Away Point: ${walk_away:,}\")\n",
        "        if confidence:\n",
        "            print(f\"   📈 Confidence:      {int(confidence * 100)}%\")\n",
        "        print()\n",
        "\n",
        "        # Career transition info\n",
        "        if analysis.get(\"is_career_transition\"):\n",
        "            print(\"⚠️  Career Transition Detected:\\n\")\n",
        "            exp_breakdown = result.get(\"experience_breakdown\", {})\n",
        "            print(f\"   Total Experience:    {exp_breakdown.get('total_years', 0)} years\")\n",
        "            print(f\"   Relevant Experience: {exp_breakdown.get('relevant_years', 0)} years\")\n",
        "            print(f\"   Level: {analysis.get('experience_level', 'Entry').title()}\")\n",
        "            print()\n",
        "\n",
        "        # Conversation scripts\n",
        "        scripts = sal.get(\"conversation_scripts\") or sal.get(\"scripts\") or []\n",
        "        if scripts:\n",
        "            print(\"💬 Conversation Scripts:\\n\")\n",
        "            for i, script in enumerate(scripts, 1):\n",
        "                print(f\"{i}. \", end=\"\")\n",
        "                for line in _wrap_text(script, width=73):\n",
        "                    print(f\"   {line}\")\n",
        "                print()\n",
        "\n",
        "        # Reasoning\n",
        "        reasoning = sal.get(\"reasoning\") or sal.get(\"explanation\") or analysis.get(\"reasoning\")\n",
        "        if reasoning:\n",
        "            print(\"📝 Strategy Reasoning:\\n\")\n",
        "            for line in _wrap_text(reasoning, width=75):\n",
        "                print(f\"   {line}\")\n",
        "            print()\n",
        "\n",
        "        # Data sources\n",
        "        sources = analysis.get(\"sources_used\", [])\n",
        "        if sources:\n",
        "            print(\"📚 Data Sources:\\n\")\n",
        "            for source in sources:\n",
        "                print(f\"   • {source}\")\n",
        "            print()\n",
        "\n",
        "    else:\n",
        "        print(\"ℹ️  No salary data or parsing failed\")\n",
        "        print(f\"\\nRaw output:\\n{str(sal_raw)[:500]}...\")\n",
        "\n",
        "    # Save to file\n",
        "    path = _save_file(\"salary_strategy\", sal, str(sal_raw))\n",
        "    print(f\"💾 Saved to: {path}\")\n",
        "\n",
        "\n",
        "def _wrap_text(text, width=70):\n",
        "    \"\"\"Word wrap text to specified width\"\"\"\n",
        "    words = str(text).split()\n",
        "    lines = []\n",
        "    current_line = []\n",
        "    current_length = 0\n",
        "\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 <= width:\n",
        "            current_line.append(word)\n",
        "            current_length += len(word) + 1\n",
        "        else:\n",
        "            if current_line:\n",
        "                lines.append(\" \".join(current_line))\n",
        "            current_line = [word]\n",
        "            current_length = len(word)\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(\" \".join(current_line))\n",
        "\n",
        "    return lines\n",
        "\n",
        "\n",
        "def pretty_print_all(result):\n",
        "    \"\"\"\n",
        "    Main function to beautifully print all CareerForge results\n",
        "\n",
        "    Usage:\n",
        "        pretty_print_all(result)\n",
        "    \"\"\"\n",
        "\n",
        "    # Header\n",
        "    print(\"\\n\" + \"=\" * 160)\n",
        "    print(\"🚀 CAREERFORGE AI - COMPLETE ANALYSIS REPORT\".center(80))\n",
        "    print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\".center(80))\n",
        "    print(\"=\" * 160)\n",
        "\n",
        "    # Print each section\n",
        "    format_job_search(result)\n",
        "    format_tailored_resume(result)\n",
        "    format_ats_analysis(result)\n",
        "    format_interview_prep(result)\n",
        "    format_salary_strategy(result)\n",
        "\n",
        "\n",
        "pretty_print_all(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
